{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome!\n\n\nThis site contains tutorials for analysing bacterial \nomics\n data.\n\n\nThe site is in draft mode. Training modules are being developed and added progressively. Please send issues or suggestions to \nAnna Syme\n at VLSCI.\n\n\nData sources\n\n\n\n\nGenomics\n\n\nTranscriptomics\n\n\nProteomics\n\n\nMetabolomics\n\n\n\n\nAnalysis platforms\n\n\n\n\nUnix command line\n\n\nGalaxy workflow system\n\n\n\n\nPlatform\n\n\n\n\nMicrobial Genomics Virtual Lab", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "This site contains tutorials for analysing bacterial  omics  data.  The site is in draft mode. Training modules are being developed and added progressively. Please send issues or suggestions to  Anna Syme  at VLSCI.", 
            "title": "Welcome!"
        }, 
        {
            "location": "/#data-sources", 
            "text": "Genomics  Transcriptomics  Proteomics  Metabolomics", 
            "title": "Data sources"
        }, 
        {
            "location": "/#analysis-platforms", 
            "text": "Unix command line  Galaxy workflow system", 
            "title": "Analysis platforms"
        }, 
        {
            "location": "/#platform", 
            "text": "Microbial Genomics Virtual Lab", 
            "title": "Platform"
        }, 
        {
            "location": "/workshop/overview/", 
            "text": "Overview\n\n\nIn this section there are five short tutorials covering basic microbial genomics analyses in Galaxy. These have been designed to run sequentially.\n\n\n\n\nUse the Galaxy Platform\n: a web-based interface for bioinformatic analyses.\n\n\nView genomes with JBrowse\n: view bacterial genomes with JBrowse.\n\n\nAssemble genomes with Spades\n: assemble raw sequence reads into a draft bacterial genome sequence using the tool \nSpades\n.\n\n\nAnnotate genomes with Prokka\n: describe the type and location of proteins and other features on the draft bacterial genome sequence using the tool \nProkka\n.\n\n\nFind variants with Snippy\n: identify differences (such as nucleotide mutations) between genomes using the tool \nSnippy\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/workshop/overview/#overview", 
            "text": "In this section there are five short tutorials covering basic microbial genomics analyses in Galaxy. These have been designed to run sequentially.   Use the Galaxy Platform : a web-based interface for bioinformatic analyses.  View genomes with JBrowse : view bacterial genomes with JBrowse.  Assemble genomes with Spades : assemble raw sequence reads into a draft bacterial genome sequence using the tool  Spades .  Annotate genomes with Prokka : describe the type and location of proteins and other features on the draft bacterial genome sequence using the tool  Prokka .  Find variants with Snippy : identify differences (such as nucleotide mutations) between genomes using the tool  Snippy .", 
            "title": "Overview"
        }, 
        {
            "location": "/workshop/genomics/1a/", 
            "text": "Introduction to Galaxy\n\n\nBackground\n\n\nGalaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.\n\n\nBioinformatics tools can be added from the Galaxy \u2018tool shed\u2019 or removed as necessary from your Galaxy instance.\n\n\nGalaxy is an open, web-based platform. Details about the project can be found \nhere\n.\n\n\nThe Galaxy interface is separated into three parts. The \nTools\n list on the left, the \nViewing\n panel in the middle and the analysis and data \nHistory\n on the right. We will be looking at all three parts in this tutorial.\n\n\n\n\nThis activity will familiarise you with the Galaxy interface. It will cover the following operations:\n\n\n\n\nLogging in to the server\n\n\nPutting data onto Galaxy\n\n\nUsing some common tools\n\n\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nRegister and login to a Galaxy server.\n\n\nUpload data to a Galaxy server from:\n\n\nA file on your local computer.\n\n\nA file on a remote datastore with an accessible URL.  \n\n\n\n\n\n\nUse tools in Galaxy by:\n\n\nAccessing the tool via the tool menu.\n\n\nUsing the tool interface to run the particular tool.\n\n\nViewing/accessing the tool output.\n\n\n\n\n\n\n\n\nLogin to Galaxy\n\n\n\n\nOpen a new tab or window on your web browser.\n\n\nUse Firefox or Chrome - please don\u2019t use Internet Explorer or Safari.\n\n\nIn the address bar, type in the address of your galaxy server. Alternatively, you can access galaxy via the dashboard of your mGVL.\n\n\n\n\n\n\n\n\n\n\nClick on \nUser\n button on the right and either register or login.\n\n\n\n\n\n\n\n\nIf you haven\nt yet registered, \nRegister:\n\n\n\n\nSelect: \nUser \n Register\n\n\nEnter your email, choose a password, and choose a user name.\n\n\nClick \nSubmit\n\n\n\n\nIf you have already registered, \nLogin:\n\n\n\n\nSelect: \nUser \n Login\n\n\nEnter your username \n password.\n\n\nClick \nSubmit\n\n\n\n\nPut data onto Galaxy\n\n\nThere are two main ways to put your data onto Galaxy; this section will run through both ways. First, we need to make a new history.\n\n\nMake a new history\n\n\nFirst, make a new folder to store the work we are about to perform.\n\n\n\n\nClick on the history menu button \n at the top of the \nHistory\n panel.\n\n\nSelect \nCreate New\n\n\nClick on \nUnnamed history\n to rename. Type in a new name.\n\n\n\n\nDatatypes\n\n\nWhat sort of file is being uploaded?\n\n\nWe need to tell Galaxy what sort of file is being uploaded. Some common datatypes (file formats) are: text, FASTA, FASTQ, VCF, GFF, GBK, and tabular.\n\n\n\nUpload a file from your own computer\n\n\nWith this method you can get most of the files on your own computer into Galaxy.\n\n\nFirst, download the following file to your computer:\n\n\n\n\nCopy this URL and paste it into the address bar in your web browser: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/galaxy101/Contig_stats.txt.gz\n\nThis is a file stored on the cloud. Press \nEnter\n, and the file will download. Note the download location.\n\n\n\n\n\n\n\n\n\n\nNext, upload that file to Galaxy\n\n\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nChoose local file\n button  \n\n\nFind and select the \nContig_stats.txt.gz\n file you downloaded and click \nOpen\n  \n\n\nSet the \nType\n to \ntabular\n  \n\n\nClick the \nStart\n button  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.\n\n\n\n\nUpload a file from a URL\n\n\nIf a file exists on a web resource somewhere and you know its URL (Unique Resource Location - a web address) you can directly load it into Galaxy.\n\n\n\n\nFrom the tool panel, click on \nGet Data \n Upload File\n\n\nClick on the \nPaste/Fetch Data\n button\n\n\nCopy and paste the following web address into the URL/Text box:\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/COMP90014/Assignment1/bacterial_std_err_1.fastq.gz\n\n\nSet the \nType\n to \nfastqsanger\n (CAREFUL: not fastqCsanger)\n\n\nClick \nStart\n\n\nOnce the progress bar has reached 100%, click \nClose\n.\n\n\nNote that Galaxy is smart enough to recognize that this is a compressed file and so it will uncompress it as it loads it.\n\n\n\n\nUpload another file from a URL\n\n\nNow we are going to upload another file from the remote data source.\n\n\n\n\nRepeat the above for: https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/MRSA0252.fna\n\n\nNote: this file \nType\n is \nFASTA\n.\n\n\nThe DNA sequence of \nStaphylococcus aureus MRSA252\n will be loaded into your history as a FASTA file.\n\n\nYour \nHistory\n should now look like this:\n\n\n\n\n\n\nThe data\n\n\nA brief description of each of the three files uploaded to Galaxy:  \n\n\nContigs_stats.txt\n  \n\n\n\n\nthis file contains a table of summary data from a \nde novo\n genome assembly (the process of attempting to recover the full genome of an organism from the short read sequences produced by most DNA sequencing machines).\n\n\nThe columns contain a lot of information but the ones we will be using indicate the amount of data (or coverage) that went into making up each piece of the final assembly.\n\n\n\n\nbacterial_std_err_1.fastq.gz\n  \n\n\n\n\nThis file contains sequence reads, in the format produced by Illumina sequencing machines. Read more about the\n\nFASTQ\n format at Wikipedia.\n\n\n\n\nMRSA0252.fna\n\n\n\n\nThis file contains the genome sequence of \nStaphylococcus aureus MRSA252\n. Read more about the \nFASTA\n format at Wikipedia.\n\n\n\n\nGalaxy tools\n\n\nThe purpose of this section is to help you become familiar with the way\ntools are run on Galaxy.\n\n\nWe will see how to:\n\n\n\n\nrename files\n\n\nsummarize assembly statistics\n\n\nconvert file formats, and\n\n\nfind features in a DNA sequence.\n\n\n\n\nRename files\n\n\nTwo of the files in the \nHistory\n have very long and confusing names. File names can be changed by taking the following steps:\n\n\n\n\nClick on the edit icon \n next to the file in the \nHistory\n called: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/COMP90014/Assignment1/bacterial_std_err_1.fastq\n\n\nIn the \nName\n text box, give it a new name. Rename it to: \ntypical.fastq\n\n\nClick the \nSave\n button.\n\n\n\n\nRepeat the process with another file:\n\n\n\n\nFind the file called: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/MRSA0252.fna\n  \n\n\nRename it to \nMRSA252.fna\n\n\n\n\nMuch better. There is other functionality hidden behind that edit icon \n\n\nYou can change a file\u2019s datatype, convert its format and many other things. Feel free to play around with them at a later date.\n\n\nSummarize assembly statistics\n\n\nWe are going to produce a histogram of contig read-coverage depths and calculate the summary statistics from the \nContig_stats.txt\n file.\n\n\nTo do this we need to make some changes to the \nContig_stats.txt\n file:\n\n\n\n\ncut out a couple of columns from the file\n\n\nremove a line from the file\n\n\nproduce a histogram\n\n\n\n\nCut out and keep two columns\n\n\n\n\nClick on the eye icon \n of the \nContig_stats.txt\n file to have a look at it.  \n\n\nNote that there are 18 columns in this file. We want column 1 and column 6.\n\n\nGo to \nTools \n Text Manipulation \n Cut\n and set the following:\n\n\nSet \nCut Columns\n to: \nc1,c6\n\n\nDelimited by\n: \nTab\n\n\nFrom\n: \nContig_stats.txt\n\n\nClick \nExecute\n\n\nExamine the new file by clicking on its eye icon \n. We now have 2 columns instead of the 18 in the original file.\n\n\n\n\nRemove the Header lines of the new file\n\n\n\n\nGo to \nTools \n Text Manipulation \n Remove beginning\n and set the following:\n\n\nRemove First\n: \n1\n\n\nfrom\n: \nCut on data1\n\n\nclick \nExecute\n\n\nNote the the new file is the same as the previous one without the header line.\n\n\n\n\nMake a histogram\n\n\n\n\nGo to \nTools \n Graph/Display Data \n Histogram\n and set the following:\n\n\nDataset\n: \nRemove beginning on Data 4\n\n\nNumerical column for X axis\n Column: 2\n\n\nNumber of breaks\n: \n25\n\n\nPlot title\n: \nHistogram of Contig Coverage\n\n\nLabel for X axis\n: \nCoverage depth\n\n\nClick \nExecute\n\n\nClick on the eye icon \n of the histogram to have a look at it. Note there are a few peaks. Maybe these correspond to single, double and triple copy number of these contigs.\n\n\n\n\nCalculate summary statistics for contig coverage depth\n\n\n\n\nGo to \nTools \n Statistics and Visualisation \n Statistics \n Summary Statisitics\n and set the following:  \n\n\nSummary statistics on\n: \nRemove beginning on Data 4\n\n\nColumn or expression\n: \nc2\n\n\nClick \nExecute\n\n\nYou\u2019ll note that the summary statistics tool failed (red background in the \nHistory\n). There was an error!\n\n\nIf you click on the filename, and then the bug symbol \n, it will tell you what went wrong. (There is a missing python library).\n\n\nAt this point, you would normally contact your Galaxy server administrator.\n\n\n\n\nConvert file formats\n\n\nThis shows how to convert a FASTQ file to a FASTA file. The tool creates a new file with the converted data.\n\n\n\n\nGo to \nTools \n Basic Tools \n Convert Formats \n FASTQ to FASTA\n and set the following:\n\n\nFASTQ file to convert\n: \ntypical.fastq\n\n\nClick \nExecute\n\n\nThe output is a new Fasta file called \nFASTQ to FASTA on data 2\n.\n\n\n\n\nFind features\n\n\nThis example shows how to use a tool called \u201cbarrnap\u201d to search for rRNAs in a DNA sequence.\n\n\nFind all of the ribosomal RNAs in a sequence\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Annotation \n barrnap\n and set the following:\n\n\nFasta file\n: \nMRSA252.fna\n\n\nClick \nExecute\n\n\nThe output is \nbarrnap on data 3\n It is a gff3 format file (general feature format version 3). Each line in the file describes a feature in the DNA sequence.\n\n\n\n\nFilter the annotations to get the 23S RNAs\n\n\n\n\nMake a file with only the 23S rRNA features\n\n\nGo to \nTools \n Basic Tools \n Filter and Sort \n Select\n and set the following:\n\n\nSelect lines from\n: (whatever you called the barrnap gff3 output)\n\n\nthe pattern\n: \n23S\n (this will look for all the lines in the file that contain \u201c23S\u201d)\n\n\nClick \nExecute\n\n\nNow you have a gff3 file with just the 23S annotations!\n\n\n\n\nWhat next?\n\n\n\n\n\n\nRemember how we started a new \nHistory\n at the beginning? If you want to see any of your old histories, click on the History menu button \n at the top of the \nHistory\n panel and then select \u201cSaved Histories.\u201d This will give you a list of all the histories you have worked on in this Galaxy server.\n\n\n\n\n\n\nNext: \nLearn about JBrowse.", 
            "title": "Use Galaxy"
        }, 
        {
            "location": "/workshop/genomics/1a/#introduction-to-galaxy", 
            "text": "", 
            "title": "Introduction to Galaxy"
        }, 
        {
            "location": "/workshop/genomics/1a/#background", 
            "text": "Galaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.  Bioinformatics tools can be added from the Galaxy \u2018tool shed\u2019 or removed as necessary from your Galaxy instance.  Galaxy is an open, web-based platform. Details about the project can be found  here .  The Galaxy interface is separated into three parts. The  Tools  list on the left, the  Viewing  panel in the middle and the analysis and data  History  on the right. We will be looking at all three parts in this tutorial.   This activity will familiarise you with the Galaxy interface. It will cover the following operations:   Logging in to the server  Putting data onto Galaxy  Using some common tools", 
            "title": "Background"
        }, 
        {
            "location": "/workshop/genomics/1a/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   Register and login to a Galaxy server.  Upload data to a Galaxy server from:  A file on your local computer.  A file on a remote datastore with an accessible URL.      Use tools in Galaxy by:  Accessing the tool via the tool menu.  Using the tool interface to run the particular tool.  Viewing/accessing the tool output.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/workshop/genomics/1a/#login-to-galaxy", 
            "text": "Open a new tab or window on your web browser.  Use Firefox or Chrome - please don\u2019t use Internet Explorer or Safari.  In the address bar, type in the address of your galaxy server. Alternatively, you can access galaxy via the dashboard of your mGVL.      Click on  User  button on the right and either register or login.     If you haven t yet registered,  Register:   Select:  User   Register  Enter your email, choose a password, and choose a user name.  Click  Submit   If you have already registered,  Login:   Select:  User   Login  Enter your username   password.  Click  Submit", 
            "title": "Login to Galaxy"
        }, 
        {
            "location": "/workshop/genomics/1a/#put-data-onto-galaxy", 
            "text": "There are two main ways to put your data onto Galaxy; this section will run through both ways. First, we need to make a new history.", 
            "title": "Put data onto Galaxy"
        }, 
        {
            "location": "/workshop/genomics/1a/#make-a-new-history", 
            "text": "First, make a new folder to store the work we are about to perform.   Click on the history menu button   at the top of the  History  panel.  Select  Create New  Click on  Unnamed history  to rename. Type in a new name.", 
            "title": "Make a new history"
        }, 
        {
            "location": "/workshop/genomics/1a/#datatypes", 
            "text": "What sort of file is being uploaded?  We need to tell Galaxy what sort of file is being uploaded. Some common datatypes (file formats) are: text, FASTA, FASTQ, VCF, GFF, GBK, and tabular.", 
            "title": "Datatypes"
        }, 
        {
            "location": "/workshop/genomics/1a/#upload-a-file-from-your-own-computer", 
            "text": "With this method you can get most of the files on your own computer into Galaxy.", 
            "title": "Upload a file from your own computer"
        }, 
        {
            "location": "/workshop/genomics/1a/#first-download-the-following-file-to-your-computer", 
            "text": "Copy this URL and paste it into the address bar in your web browser:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/galaxy101/Contig_stats.txt.gz \nThis is a file stored on the cloud. Press  Enter , and the file will download. Note the download location.", 
            "title": "First, download the following file to your computer:"
        }, 
        {
            "location": "/workshop/genomics/1a/#next-upload-that-file-to-galaxy", 
            "text": "From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Choose local file  button    Find and select the  Contig_stats.txt.gz  file you downloaded and click  Open     Set the  Type  to  tabular     Click the  Start  button    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.", 
            "title": "Next, upload that file to Galaxy"
        }, 
        {
            "location": "/workshop/genomics/1a/#upload-a-file-from-a-url", 
            "text": "If a file exists on a web resource somewhere and you know its URL (Unique Resource Location - a web address) you can directly load it into Galaxy.   From the tool panel, click on  Get Data   Upload File  Click on the  Paste/Fetch Data  button  Copy and paste the following web address into the URL/Text box: https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/COMP90014/Assignment1/bacterial_std_err_1.fastq.gz  Set the  Type  to  fastqsanger  (CAREFUL: not fastqCsanger)  Click  Start  Once the progress bar has reached 100%, click  Close .  Note that Galaxy is smart enough to recognize that this is a compressed file and so it will uncompress it as it loads it.", 
            "title": "Upload a file from a URL"
        }, 
        {
            "location": "/workshop/genomics/1a/#upload-another-file-from-a-url", 
            "text": "Now we are going to upload another file from the remote data source.   Repeat the above for: https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/MRSA0252.fna  Note: this file  Type  is  FASTA .  The DNA sequence of  Staphylococcus aureus MRSA252  will be loaded into your history as a FASTA file.  Your  History  should now look like this:", 
            "title": "Upload another file from a URL"
        }, 
        {
            "location": "/workshop/genomics/1a/#the-data", 
            "text": "A brief description of each of the three files uploaded to Galaxy:    Contigs_stats.txt      this file contains a table of summary data from a  de novo  genome assembly (the process of attempting to recover the full genome of an organism from the short read sequences produced by most DNA sequencing machines).  The columns contain a lot of information but the ones we will be using indicate the amount of data (or coverage) that went into making up each piece of the final assembly.   bacterial_std_err_1.fastq.gz      This file contains sequence reads, in the format produced by Illumina sequencing machines. Read more about the FASTQ  format at Wikipedia.   MRSA0252.fna   This file contains the genome sequence of  Staphylococcus aureus MRSA252 . Read more about the  FASTA  format at Wikipedia.", 
            "title": "The data"
        }, 
        {
            "location": "/workshop/genomics/1a/#galaxy-tools", 
            "text": "The purpose of this section is to help you become familiar with the way\ntools are run on Galaxy.  We will see how to:   rename files  summarize assembly statistics  convert file formats, and  find features in a DNA sequence.", 
            "title": "Galaxy tools"
        }, 
        {
            "location": "/workshop/genomics/1a/#rename-files", 
            "text": "Two of the files in the  History  have very long and confusing names. File names can be changed by taking the following steps:   Click on the edit icon   next to the file in the  History  called:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/COMP90014/Assignment1/bacterial_std_err_1.fastq  In the  Name  text box, give it a new name. Rename it to:  typical.fastq  Click the  Save  button.   Repeat the process with another file:   Find the file called:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/MRSA0252.fna     Rename it to  MRSA252.fna   Much better. There is other functionality hidden behind that edit icon   You can change a file\u2019s datatype, convert its format and many other things. Feel free to play around with them at a later date.", 
            "title": "Rename files"
        }, 
        {
            "location": "/workshop/genomics/1a/#summarize-assembly-statistics", 
            "text": "We are going to produce a histogram of contig read-coverage depths and calculate the summary statistics from the  Contig_stats.txt  file.  To do this we need to make some changes to the  Contig_stats.txt  file:   cut out a couple of columns from the file  remove a line from the file  produce a histogram", 
            "title": "Summarize assembly statistics"
        }, 
        {
            "location": "/workshop/genomics/1a/#cut-out-and-keep-two-columns", 
            "text": "Click on the eye icon   of the  Contig_stats.txt  file to have a look at it.    Note that there are 18 columns in this file. We want column 1 and column 6.  Go to  Tools   Text Manipulation   Cut  and set the following:  Set  Cut Columns  to:  c1,c6  Delimited by :  Tab  From :  Contig_stats.txt  Click  Execute  Examine the new file by clicking on its eye icon  . We now have 2 columns instead of the 18 in the original file.", 
            "title": "Cut out and keep two columns"
        }, 
        {
            "location": "/workshop/genomics/1a/#remove-the-header-lines-of-the-new-file", 
            "text": "Go to  Tools   Text Manipulation   Remove beginning  and set the following:  Remove First :  1  from :  Cut on data1  click  Execute  Note the the new file is the same as the previous one without the header line.", 
            "title": "Remove the Header lines of the new file"
        }, 
        {
            "location": "/workshop/genomics/1a/#make-a-histogram", 
            "text": "Go to  Tools   Graph/Display Data   Histogram  and set the following:  Dataset :  Remove beginning on Data 4  Numerical column for X axis  Column: 2  Number of breaks :  25  Plot title :  Histogram of Contig Coverage  Label for X axis :  Coverage depth  Click  Execute  Click on the eye icon   of the histogram to have a look at it. Note there are a few peaks. Maybe these correspond to single, double and triple copy number of these contigs.", 
            "title": "Make a histogram"
        }, 
        {
            "location": "/workshop/genomics/1a/#calculate-summary-statistics-for-contig-coverage-depth", 
            "text": "Go to  Tools   Statistics and Visualisation   Statistics   Summary Statisitics  and set the following:    Summary statistics on :  Remove beginning on Data 4  Column or expression :  c2  Click  Execute  You\u2019ll note that the summary statistics tool failed (red background in the  History ). There was an error!  If you click on the filename, and then the bug symbol  , it will tell you what went wrong. (There is a missing python library).  At this point, you would normally contact your Galaxy server administrator.", 
            "title": "Calculate summary statistics for contig coverage depth"
        }, 
        {
            "location": "/workshop/genomics/1a/#convert-file-formats", 
            "text": "This shows how to convert a FASTQ file to a FASTA file. The tool creates a new file with the converted data.   Go to  Tools   Basic Tools   Convert Formats   FASTQ to FASTA  and set the following:  FASTQ file to convert :  typical.fastq  Click  Execute  The output is a new Fasta file called  FASTQ to FASTA on data 2 .", 
            "title": "Convert file formats"
        }, 
        {
            "location": "/workshop/genomics/1a/#find-features", 
            "text": "This example shows how to use a tool called \u201cbarrnap\u201d to search for rRNAs in a DNA sequence.", 
            "title": "Find features"
        }, 
        {
            "location": "/workshop/genomics/1a/#find-all-of-the-ribosomal-rnas-in-a-sequence", 
            "text": "Go to  Tools   NGS Analysis   NGS: Annotation   barrnap  and set the following:  Fasta file :  MRSA252.fna  Click  Execute  The output is  barrnap on data 3  It is a gff3 format file (general feature format version 3). Each line in the file describes a feature in the DNA sequence.", 
            "title": "Find all of the ribosomal RNAs in a sequence"
        }, 
        {
            "location": "/workshop/genomics/1a/#filter-the-annotations-to-get-the-23s-rnas", 
            "text": "Make a file with only the 23S rRNA features  Go to  Tools   Basic Tools   Filter and Sort   Select  and set the following:  Select lines from : (whatever you called the barrnap gff3 output)  the pattern :  23S  (this will look for all the lines in the file that contain \u201c23S\u201d)  Click  Execute  Now you have a gff3 file with just the 23S annotations!", 
            "title": "Filter the annotations to get the 23S RNAs"
        }, 
        {
            "location": "/workshop/genomics/1a/#what-next", 
            "text": "Remember how we started a new  History  at the beginning? If you want to see any of your old histories, click on the History menu button   at the top of the  History  panel and then select \u201cSaved Histories.\u201d This will give you a list of all the histories you have worked on in this Galaxy server.    Next:  Learn about JBrowse.", 
            "title": "What next?"
        }, 
        {
            "location": "/workshop/genomics/1c/", 
            "text": "JBrowse", 
            "title": "View with JBroswe"
        }, 
        {
            "location": "/workshop/genomics/1c/#jbrowse", 
            "text": "", 
            "title": "JBrowse"
        }, 
        {
            "location": "/workshop/genomics/2a/", 
            "text": "Assembly using Spades\n\n\nBackground\n\n\nSpades is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this \nlink\n.\n\n\n\n\n\nIn this activity, we will perform a \nde novo\n assembly of a short read set using the Spades assembler. The output from Spades that we are interested in is a multifasta file that contains the draft genome sequence.\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome.\n\n\nWe have a closed, annotated genome sequence for a closely related \nwildtype\n strain.\n\n\nThe whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\nThe reads are paired-end\n\n\nEach read is 150 bases (before trimming)\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nimport data into Galaxy  \n\n\nview the files\n\n\nevaluate the read quality\n\n\nassemble the reads using Spades, and\n\n\nexamine the output assembly.\n\n\n\n\nImport data into Galaxy\n\n\n\n\nGo to the address of your galaxy server.\n\n\n\n\n\n\n\n\n\nClick on the \nAnalyze Data\n menu at the top of the page.    \n\n\nClick on the \nHistory options\n button the \n on the top right of the history pane.\n\n\nClick \nImport from File\n (at the bottom of the list).  \n\n\nA new page will appear with a text box for the URL of the history to import.  \n\n\nCopy the following URL into the text box: \nhttp://43.240.98.1/public/dieter/Galaxy-History-Colombiaworkshopstart.tar.gz\n  \n\n\nClick \nSubmit\n.  \n\n\nGalaxy will download the data files from the internet and will be available as an additional history (takes about one minute).  \n\n\nTo view this new history, click the \nView all histories\n button\n (top right of the history pane).  \n\n\nIf the history has finished downloading it will appear as \nimported from archive: Colombia_workshop_start\n\n\nClick on the \n button above the \nimported from archive:Colombia_workshop_start\n then the \n button.\n\n\nYou should now have four files in the history pane as follows:\n\n\n\n\n\n\nView files\n\n\nAll the files are text files.\n\n\n\n\nmutant_R1.fastq\n and \nmutant_R2.fastq\n: a paired-end read set  \n\n\nwildtype.fna\n: a file that contains the genome sequence of the wildtype strain in fasta format (a header line, then the nucleotide sequence of the genome)\n\n\nwildtype.gff\n: a file that contains the genome sequence of the wildtype strain in general feature format. (a list of features - one feature per line, then the nucleotide sequence of the genome)\n\n\n\n\nLook at the contents of these files.\n\n\n\n\nClick on the View Data button (the \n) next to each of the files in turn.\n\n\nThe gff file should look like this:\n\n\n\n\n\n\n\n\n\nEvaluate the input reads\n\n\nQuestions you might ask about your input reads include:\n\n\n\n\nHow good is my read set?\n\n\nDo I need to ask for a new sequencing run?  \n\n\nIs it suitable for the analysis I need to do?\n\n\n\n\nWe will evaluate the input reads using the FastQC tool.\n\n\n\n\nThis runs a standard series of tests on your read set and returns a relatively easy-to-interpret report.\n\n\nWe will use the FastQC tool in Galaxy to evaluate the quality of one of our FASTQ files.\n\n\nGo to \nTools \n NGS:Analysis \n NGS: QC and Manipulation \n FastQC\n\n\nSelect \nmutant_R1.fastq\n\n\nExecute\n\n\nOnce finished, examine the output called \nFastQC on data1:webpage\n (Hint:\n). It has a summary at the top of\nthe page and a number of graphs.\n\n\n\n\nSome of the important outputs of FastQC for our purposes are:\n\n\n\n\nBasic Statistics: Sequence length\n: will be important in setting maximum k-mer size value for assembly\n\n\nBasic Statistics: Encoding\n: Quality encoding type: important for quality trimming software\n\n\nBasic Statistics: % GC\n: high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.\n\n\nBasic Statistics: Total sequences\n: Total number of reads: gives you an idea of coverage.\n\n\nPer base sequence quality\n: Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.\n\n\nPer base N content\n: Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.\n\n\nKmer content\n: Presence of highly recurring k-mers: may point to contamination of reads with barcodes or adapter sequences.\n\n\n\n\nAlthough we have warnings for two outputs (per base sequence content; Kmer content), we can ignore these for now. For a fuller discussion of FastQC outputs and warnings, see the \nFastQC website link\n, including the section on each of the output \nreports\n, and examples of \ngood\n and \nbad\n Illumina data. We won\u2019t be doing anything to these data to clean it up as there isn\u2019t much need. Therefore we will get on with the assembly!\n\n\nAssemble reads with Spades\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\n\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n spades\n\n\n\n\nSet the following parameters:\n\n\n\n\nRun only Assembly\n: \nYes\n  \n\n\nKmers to use separated by commas:\n \n33,55,91\n  [no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\nFiles \n Forward reads:\n \nmutant_R1.fastq\n  \n\n\nFiles \n Reverse reads:\n \nmutant_R2.fastq\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running Spades on the reads for you.\n\n\n\n\nWhen it is finished, you will have five new files in your history.  \n\n\n\n\ntwo FASTA files of the resulting contigs and scaffolds\n\n\ntwo files for statistics about these\n\n\nthe Spades logfile\n\n\n\n\n\n\n\n\nClick on the View Data button \n on each of the files.\n\n\n\n\nNote that the short reads have been assembled into much longer contigs.\n\n\n(However, in this case, the contigs have not been assembled into larger scaffolds.)\n\n\nThe stats files will give you the length of each of the contigs.\n\n\n\n\nWhat next?\n\n\n\n\nAnnotate the genome using Prokka.", 
            "title": "Assemble with Spades"
        }, 
        {
            "location": "/workshop/genomics/2a/#assembly-using-spades", 
            "text": "", 
            "title": "Assembly using Spades"
        }, 
        {
            "location": "/workshop/genomics/2a/#background", 
            "text": "Spades is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this  link .   In this activity, we will perform a  de novo  assembly of a short read set using the Spades assembler. The output from Spades that we are interested in is a multifasta file that contains the draft genome sequence.  The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome.  We have a closed, annotated genome sequence for a closely related  wildtype  strain.  The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.   The reads are paired-end  Each read is 150 bases (before trimming)  The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).", 
            "title": "Background"
        }, 
        {
            "location": "/workshop/genomics/2a/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   import data into Galaxy    view the files  evaluate the read quality  assemble the reads using Spades, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/workshop/genomics/2a/#import-data-into-galaxy", 
            "text": "Go to the address of your galaxy server.     Click on the  Analyze Data  menu at the top of the page.      Click on the  History options  button the   on the top right of the history pane.  Click  Import from File  (at the bottom of the list).    A new page will appear with a text box for the URL of the history to import.    Copy the following URL into the text box:  http://43.240.98.1/public/dieter/Galaxy-History-Colombiaworkshopstart.tar.gz     Click  Submit .    Galaxy will download the data files from the internet and will be available as an additional history (takes about one minute).    To view this new history, click the  View all histories  button  (top right of the history pane).    If the history has finished downloading it will appear as  imported from archive: Colombia_workshop_start  Click on the   button above the  imported from archive:Colombia_workshop_start  then the   button.  You should now have four files in the history pane as follows:", 
            "title": "Import data into Galaxy"
        }, 
        {
            "location": "/workshop/genomics/2a/#view-files", 
            "text": "All the files are text files.   mutant_R1.fastq  and  mutant_R2.fastq : a paired-end read set    wildtype.fna : a file that contains the genome sequence of the wildtype strain in fasta format (a header line, then the nucleotide sequence of the genome)  wildtype.gff : a file that contains the genome sequence of the wildtype strain in general feature format. (a list of features - one feature per line, then the nucleotide sequence of the genome)   Look at the contents of these files.   Click on the View Data button (the  ) next to each of the files in turn.  The gff file should look like this:", 
            "title": "View files"
        }, 
        {
            "location": "/workshop/genomics/2a/#evaluate-the-input-reads", 
            "text": "Questions you might ask about your input reads include:   How good is my read set?  Do I need to ask for a new sequencing run?    Is it suitable for the analysis I need to do?   We will evaluate the input reads using the FastQC tool.   This runs a standard series of tests on your read set and returns a relatively easy-to-interpret report.  We will use the FastQC tool in Galaxy to evaluate the quality of one of our FASTQ files.  Go to  Tools   NGS:Analysis   NGS: QC and Manipulation   FastQC  Select  mutant_R1.fastq  Execute  Once finished, examine the output called  FastQC on data1:webpage  (Hint: ). It has a summary at the top of\nthe page and a number of graphs.   Some of the important outputs of FastQC for our purposes are:   Basic Statistics: Sequence length : will be important in setting maximum k-mer size value for assembly  Basic Statistics: Encoding : Quality encoding type: important for quality trimming software  Basic Statistics: % GC : high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.  Basic Statistics: Total sequences : Total number of reads: gives you an idea of coverage.  Per base sequence quality : Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.  Per base N content : Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.  Kmer content : Presence of highly recurring k-mers: may point to contamination of reads with barcodes or adapter sequences.   Although we have warnings for two outputs (per base sequence content; Kmer content), we can ignore these for now. For a fuller discussion of FastQC outputs and warnings, see the  FastQC website link , including the section on each of the output  reports , and examples of  good  and  bad  Illumina data. We won\u2019t be doing anything to these data to clean it up as there isn\u2019t much need. Therefore we will get on with the assembly!", 
            "title": "Evaluate the input reads"
        }, 
        {
            "location": "/workshop/genomics/2a/#assemble-reads-with-spades", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)     Go to  Tools   NGS Analysis   NGS: Assembly   spades   Set the following parameters:   Run only Assembly :  Yes     Kmers to use separated by commas:   33,55,91   [no spaces]    Coverage cutoff:   auto     Files   Forward reads:   mutant_R1.fastq     Files   Reverse reads:   mutant_R2.fastq        Your tool interface should look like this:      Click  Execute", 
            "title": "Assemble reads with Spades"
        }, 
        {
            "location": "/workshop/genomics/2a/#examine-the-output", 
            "text": "Galaxy is now running Spades on the reads for you.   When it is finished, you will have five new files in your history.     two FASTA files of the resulting contigs and scaffolds  two files for statistics about these  the Spades logfile     Click on the View Data button   on each of the files.   Note that the short reads have been assembled into much longer contigs.  (However, in this case, the contigs have not been assembled into larger scaffolds.)  The stats files will give you the length of each of the contigs.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/workshop/genomics/2a/#what-next", 
            "text": "Annotate the genome using Prokka.", 
            "title": "What next?"
        }, 
        {
            "location": "/workshop/genomics/2b/", 
            "text": "Genome annotation using Prokka\n\n\nBackground\n\n\nIn this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous \ntutorial\n. Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.\n\n\nProkka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using \nProdigal\n; second, the \nfunction\n of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found \nhere\n.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\ninput files into Prokka\n\n\nchange settings\n\n\nrun Prokka, and\n\n\nexamine the output: annotated genome.\n\n\n\n\nInput data\n\n\n\n\nYou will need the assembled contigs from the previous workshop (\nAssembly with Spades\n): \nSPAdes_contigs.fasta\n\n\nIf you are continuing on from that tutorial, this file will be in your current history and there is no need to find/import it.\n\n\n\n\nRun Prokka\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n  \n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nYes\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nGenus Name\n: \nStaphylococcus\n  \n\n\nSpecies Name\n: \naureus\n  \n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\nClick \nExecute\n  \n\n\n\n\n\n\n\n\nExamine the output\n\n\nOnce Prokka has finished, examine each of its output files.\n\n\n\n\nThe gff and gbk files contains all of the information about all of the features annotated (in different formats.)\n\n\nThe txt file contains a summary of the number of features annotated.\n\n\nThe faa file contains the protein sequences of the genes annotated.\n\n\n\n\nThe ffn file contains the nucleotide sequences of the genes annotated.\n\n\n\n\n\n\nDownload the gff file to your local computer: click on the file name with the .gff extension, and then click on the disk icon \n.\n\n\n\n\n\n\n\n\nAnnotated features\n\n\nNow that we have annotated the draft genome sequence, we would like to view the sequence in the Artemis genome viewer.\n\n\n\n\nOpen Artemis and load the downloaded .gff file.\n\n\nThe top panel shows an overview - here we can see annotated genes and other features.\n\n\nThe middle panel shows the DNA sequence and amino acid translations in 6 frames.\n\n\nThe bottom panel shows a text summary of the features.\n\n\nScroll left and right with the horizontal bars under each panel.\n\n\nZoom with the vertical bars to the right.\n\n\n\n\n\n\nWhat next?\n\n\n\n\nIdentify genome variants (nucletotide changes) using Snippy.", 
            "title": "Annotate with Prokka"
        }, 
        {
            "location": "/workshop/genomics/2b/#genome-annotation-using-prokka", 
            "text": "", 
            "title": "Genome annotation using Prokka"
        }, 
        {
            "location": "/workshop/genomics/2b/#background", 
            "text": "In this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous  tutorial . Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.  Prokka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using  Prodigal ; second, the  function  of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found  here .", 
            "title": "Background"
        }, 
        {
            "location": "/workshop/genomics/2b/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   input files into Prokka  change settings  run Prokka, and  examine the output: annotated genome.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/workshop/genomics/2b/#input-data", 
            "text": "You will need the assembled contigs from the previous workshop ( Assembly with Spades ):  SPAdes_contigs.fasta  If you are continuing on from that tutorial, this file will be in your current history and there is no need to find/import it.", 
            "title": "Input data"
        }, 
        {
            "location": "/workshop/genomics/2b/#run-prokka", 
            "text": "In Galaxy, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):  Contigs to annotate :  SPAdes contigs (fasta)     Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  Yes  Sequencing Centre ID ( centre) : V  Genus Name :  Staphylococcus     Species Name :  aureus     Use genus-specific BLAST database   No     Click  Execute", 
            "title": "Run Prokka"
        }, 
        {
            "location": "/workshop/genomics/2b/#examine-the-output", 
            "text": "Once Prokka has finished, examine each of its output files.   The gff and gbk files contains all of the information about all of the features annotated (in different formats.)  The txt file contains a summary of the number of features annotated.  The faa file contains the protein sequences of the genes annotated.   The ffn file contains the nucleotide sequences of the genes annotated.    Download the gff file to your local computer: click on the file name with the .gff extension, and then click on the disk icon  .", 
            "title": "Examine the output"
        }, 
        {
            "location": "/workshop/genomics/2b/#annotated-features", 
            "text": "Now that we have annotated the draft genome sequence, we would like to view the sequence in the Artemis genome viewer.   Open Artemis and load the downloaded .gff file.  The top panel shows an overview - here we can see annotated genes and other features.  The middle panel shows the DNA sequence and amino acid translations in 6 frames.  The bottom panel shows a text summary of the features.  Scroll left and right with the horizontal bars under each panel.  Zoom with the vertical bars to the right.", 
            "title": "Annotated features"
        }, 
        {
            "location": "/workshop/genomics/2b/#what-next", 
            "text": "Identify genome variants (nucletotide changes) using Snippy.", 
            "title": "What next?"
        }, 
        {
            "location": "/workshop/genomics/3b/", 
            "text": "Variant calling with Snippy", 
            "title": "Find variants with Snippy"
        }, 
        {
            "location": "/workshop/genomics/3b/#variant-calling-with-snippy", 
            "text": "", 
            "title": "Variant calling with Snippy"
        }, 
        {
            "location": "/how_to/overview/", 
            "text": "Overview - Advanced Training\n\n\nThis section contains training modules for microbial genomics analyses. All analyses are performed using the microbial GVL (and occasionally, additional web-based tools), via the Galaxy interface or using the commandline.\n\n\n\n\n\n\nGenome assembly: from raw DNA sequence reads to assembled genome.\n\n\n\n\nin Galaxy\n - using Illumina data\n\n\non the commandline - using Illumina data\n\n\nin the mGVL SMRTPortal - using PacBio data\n\n\non the commandline - using both PacBio data and Illumina data\n\n\n\n\n\n\n\n\nGenome annotation: from assembled genome to annotated genome.\n\n\n\n\nin Galaxy\n\n\non the commandline\n\n\n\n\n\n\n\n\nCore and pan genomes: from assembled genomes to lists of shared genes and accessory genes.\n\n\n\n\non the commandline\n\n\n\n\n\n\n\n\nDifferential gene expression: from raw RNA sequence reads from two conditions to a list of differentially expressed genes.\n\n\n\n\nin Galaxy\n\n\n\n\n\n\n\n\nFor more information about using the GVL see \nhttp://genome.edu.au", 
            "title": "Overview"
        }, 
        {
            "location": "/how_to/overview/#overview-advanced-training", 
            "text": "This section contains training modules for microbial genomics analyses. All analyses are performed using the microbial GVL (and occasionally, additional web-based tools), via the Galaxy interface or using the commandline.    Genome assembly: from raw DNA sequence reads to assembled genome.   in Galaxy  - using Illumina data  on the commandline - using Illumina data  in the mGVL SMRTPortal - using PacBio data  on the commandline - using both PacBio data and Illumina data     Genome annotation: from assembled genome to annotated genome.   in Galaxy  on the commandline     Core and pan genomes: from assembled genomes to lists of shared genes and accessory genes.   on the commandline     Differential gene expression: from raw RNA sequence reads from two conditions to a list of differentially expressed genes.   in Galaxy     For more information about using the GVL see  http://genome.edu.au", 
            "title": "Overview - Advanced Training"
        }, 
        {
            "location": "/how_to/assembly/assembly_galaxy/", 
            "text": "Assembly - Galaxy", 
            "title": "Genome assembly in Galaxy"
        }, 
        {
            "location": "/how_to/assembly/assembly_galaxy/#assembly-galaxy", 
            "text": "", 
            "title": "Assembly - Galaxy"
        }, 
        {
            "location": "/how_to/annotation/anno_galaxy/", 
            "text": "Annotation - Galaxy", 
            "title": "Genome annotation in Galaxy"
        }, 
        {
            "location": "/how_to/annotation/anno_galaxy/#annotation-galaxy", 
            "text": "", 
            "title": "Annotation - Galaxy"
        }, 
        {
            "location": "/how_to/pan/roary/", 
            "text": "Roary", 
            "title": "Pan genomes"
        }, 
        {
            "location": "/how_to/pan/roary/#roary", 
            "text": "", 
            "title": "Roary"
        }, 
        {
            "location": "/tools/", 
            "text": "Tools\n\n\nThis section includes short training modules about the various tools in the microbial GVL, either within the Galaxy interface or via the commandline. Additional relevant tools and software are also included, particularly for visualization.", 
            "title": "Oveview"
        }, 
        {
            "location": "/tools/#tools", 
            "text": "This section includes short training modules about the various tools in the microbial GVL, either within the Galaxy interface or via the commandline. Additional relevant tools and software are also included, particularly for visualization.", 
            "title": "Tools"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/", 
            "text": "FastQC in Galaxy\n\n\nFIXME: include screenshots\n\n\nFIXME: include file location and/or choose different input.\n\n\nIntroduction\n\n\nAfter sequencing, the reads should be checked for their quality. This tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end sequence reads from Illumina. The FastQC website is \nhere.\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nrun FastQC on input sequence reads, and\n\n\nexamine the FastQC output.\n\n\n\n\nInput files\n\n\ne.g. \nmutant_R1.fastq\n and \nmutant_R2.fastq\n: a paired-end read set\n\nFIXME: or alternative. Ideally with contaminants/etc. ?\n\n\nWe will evaluate the R1 input reads using the FastQC tool.\n\n\nRun FastQC\n\n\n\n\nGo to \nTools \n NGS:Analysis \n NGS: QC and Manipulation \n FastQC\n\n\nfor \nShort read data from your current history\n: \nmutant_R1.fastq\n\n\nClick \nExecute\n\n\n\n\nExamine output files\n\n\nOnce finished, examine the output called \nFastQC on data1:webpage\n (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.\n\n\nLook at:\n\n\n\n\nBasic Statistics: Sequence length\n: will be important in setting maximum k-mer size value for assembly\n\n\nBasic Statistics: Encoding\n: Quality encoding type: important for quality trimming software\n\n\nBasic Statistics: % GC\n: high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.\n\n\nBasic Statistics: Total sequences\n: Total number of reads: gives you an idea of coverage.\n\n\nPer base sequence quality\n: Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.\n\n\nPer base N content\n: Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.\n\n\nKmer content\n: Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc.\n\n\n\n\nWe have warnings for two outputs (per base sequence content; Kmer content). This would warrant more investigation.\n\n\nGeneral questions you might ask about your input reads include:\n\n\n\n\nHow good is my read set?\n\n\nDo I need to ask for a new sequencing run?  \n\n\nIs it suitable for the analysis I need to do?\n\n\n\n\nFor a fuller discussion of FastQC outputs and warnings, see the \nFastQC website link\n, including the section on each of the output \nreports\n, and examples of \ngood\n and \nbad\n Illumina data.\n\n\nWhat Next?\n\n\n\n\nTrim reads with \nTrimmomatic.\n\n\n\n\nFIXME: include these?\n\n\n\n\n\n\nlink to a fastqc protocol:\nhttp://vlsci.github.io/lscc_docs/tutorials/assembly/assembly-protocol/#section-1-read-quality-control\n\n\n\n\n\n\nmore detailed information:\nhttps://docs.google.com/document/pub?id=16GwPmwYW7o_r-ZUgCu8-oSBBY1gC97TfTTinGDk98Ws", 
            "title": "FastQC in Galaxy"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#fastqc-in-galaxy", 
            "text": "FIXME: include screenshots  FIXME: include file location and/or choose different input.", 
            "title": "FastQC in Galaxy"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#introduction", 
            "text": "After sequencing, the reads should be checked for their quality. This tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end sequence reads from Illumina. The FastQC website is  here.", 
            "title": "Introduction"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   run FastQC on input sequence reads, and  examine the FastQC output.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#input-files", 
            "text": "e.g.  mutant_R1.fastq  and  mutant_R2.fastq : a paired-end read set \nFIXME: or alternative. Ideally with contaminants/etc. ?  We will evaluate the R1 input reads using the FastQC tool.", 
            "title": "Input files"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#run-fastqc", 
            "text": "Go to  Tools   NGS:Analysis   NGS: QC and Manipulation   FastQC  for  Short read data from your current history :  mutant_R1.fastq  Click  Execute", 
            "title": "Run FastQC"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#examine-output-files", 
            "text": "Once finished, examine the output called  FastQC on data1:webpage  (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.  Look at:   Basic Statistics: Sequence length : will be important in setting maximum k-mer size value for assembly  Basic Statistics: Encoding : Quality encoding type: important for quality trimming software  Basic Statistics: % GC : high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.  Basic Statistics: Total sequences : Total number of reads: gives you an idea of coverage.  Per base sequence quality : Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.  Per base N content : Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.  Kmer content : Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc.   We have warnings for two outputs (per base sequence content; Kmer content). This would warrant more investigation.  General questions you might ask about your input reads include:   How good is my read set?  Do I need to ask for a new sequencing run?    Is it suitable for the analysis I need to do?   For a fuller discussion of FastQC outputs and warnings, see the  FastQC website link , including the section on each of the output  reports , and examples of  good  and  bad  Illumina data.", 
            "title": "Examine output files"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc/#what-next", 
            "text": "Trim reads with  Trimmomatic.   FIXME: include these?    link to a fastqc protocol:\nhttp://vlsci.github.io/lscc_docs/tutorials/assembly/assembly-protocol/#section-1-read-quality-control    more detailed information:\nhttps://docs.google.com/document/pub?id=16GwPmwYW7o_r-ZUgCu8-oSBBY1gC97TfTTinGDk98Ws", 
            "title": "What Next?"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/", 
            "text": "FastQC - commandline\n\n\nStart\n\n\n\n\non your local machine, make sure XQuartz is installed (but it doesn\nt have to be open - it will open automatically later).\n\n\nin terminal, ssh to your virtual machine with -X and -Y, e.g. \nssh -X -Y ubuntu@111.111.111.111\n (the -X and -Y means it will use your local XQuartz to display some files).\n\n\nmodule load fastqc_dist_0_10_1\n [FIXME: this may have a different name/ or be already loaded)\n\n\nnavigate to where you want to make a FastQC analysis folder.\n\n\nMake a folder: \nmkdir fastqc_analyses\n\n\nMove to that folder: \ncd fastqc_analyses\n\n\n\n\nInput\n\n\n\n\n[FIXME: get the data into this folder]\n\n\n\n\nRun\n\n\n\n\nfastqc R1reads.fastq\n [runs fastqc]\n\n\ntype \nfastqc --help\n to see settings that you can change, and defaults\n\n\nFIXME: any to change\n\n\nFIXME: repeat for R2reads?\n\n\n\n\nOutput\n\n\n\n\nR1reads_fastqc: folder containing the output, e.g. \nfastqc_report.html\n\n\nto view this, type: \nfirefox fastqc_report.html\n - firefox should open and display the report\n(you may get an error message in terminal but ignore this)", 
            "title": "FastQC on commandline"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/#fastqc-commandline", 
            "text": "", 
            "title": "FastQC - commandline"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/#start", 
            "text": "on your local machine, make sure XQuartz is installed (but it doesn t have to be open - it will open automatically later).  in terminal, ssh to your virtual machine with -X and -Y, e.g.  ssh -X -Y ubuntu@111.111.111.111  (the -X and -Y means it will use your local XQuartz to display some files).  module load fastqc_dist_0_10_1  [FIXME: this may have a different name/ or be already loaded)  navigate to where you want to make a FastQC analysis folder.  Make a folder:  mkdir fastqc_analyses  Move to that folder:  cd fastqc_analyses", 
            "title": "Start"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/#input", 
            "text": "[FIXME: get the data into this folder]", 
            "title": "Input"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/#run", 
            "text": "fastqc R1reads.fastq  [runs fastqc]  type  fastqc --help  to see settings that you can change, and defaults  FIXME: any to change  FIXME: repeat for R2reads?", 
            "title": "Run"
        }, 
        {
            "location": "/dna/qualitycontrol/fastqc_cmdline/#output", 
            "text": "R1reads_fastqc: folder containing the output, e.g.  fastqc_report.html  to view this, type:  firefox fastqc_report.html  - firefox should open and display the report\n(you may get an error message in terminal but ignore this)", 
            "title": "Output"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/", 
            "text": "Trimmomatic on Galaxy\n\n\nIntroduction\n\n\nAfter checking your input sequence reads for quality (e.g. using FastQC) it might be necessary to trim the reads. Here we will use the Trimmomatic tool. For more inforamtion, see the Trimmomatic \nwebpage\n and the \nmanual.\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\ninput sequence reads to Trimmomatic\n\n\ntrim using appropriate parameters, and\n\n\nexamine the output trimmed reads.\n\n\n\n\nStart\n\n\n\n\nopen your Galaxy instance\n\n\nfind your quality-checked Illumina sequence reads\n\n\ne.g. \nmutant_R1.fastq\n and \nmutant_R2.fastq\n\n\nWe want to trim the parts of the reads that are of low quality\n\n\nbased on the FastQC results, say we want to trim the reads like this:\n(FIXME: expand detail)\n\n\ntrim Illumina adapters\n\n\nleading and trailing bases - trim if quality is below 15\n\n\nsliding window - trim once average quality is below 20\n\n\n\n\n\n\n\n\nTrimmomatic functions\n\n\n[from LSCC docs]\n\n\n\n\n\n\nAdapter trimming\n\n\n\n\nThis function trims adapters, barcodes and other contaminants from the reads.\n\n\nYou need to supply a fasta file of possible adapter sequences, barcodes etc to trim. See Trimmomatic website for detailed instructions.\n\n\nThe default quality settings are sensible.\n\n\nThis should always be the first trimming step if it is used.\n\n\n\n\n\n\n\n\nSliding window trimming\n\n\n\n\nThis function uses a sliding window to measure average quality and trims accordingly.\n\n\nThe default quality parameters are sensible for this step.\n\n\n\n\n\n\n\n\nTrailing bases quality trimming\n\n\n\n\nThis function trims bases from the end of a read if they drop below a quality threshold. e.g. If base 69 of 75 drops below the threshold, the read is cut to 68 bases.\n\n\nUse FastQC report to decide whether this step is warranted and what quality value to use. A quality threshold value of 10-15 is a good starting point.\n\n\n\n\n\n\n\n\nLeading bases quality trimming\n\n\n\n\nThis function works in a similar fashion to trailing bases trimming except it performs it at the start of the reads.\n\n\nUse FastQC report to determine if this step is warranted. If the quality of bases is poor at the beginning of reads it might be necessary.\n\n\n\n\n\n\n\n\nMinimum read length\n\n\n\n\nOnce all trimming steps are complete, this function makes sure that the reads are still longer than this value. If not, the read is removed from the file and its pair is put into the orphan file.\n\n\nThe most appropriate value for this parameter will depend on the FastQC report, specifically the length of the high quality section of the Per Base Sequence Quality graph.\n\n\n\n\n\n\n\n\nEach read library should be trimmed separately with parameters dependent on their own FastQC reports.\n\n\n\n\n\n\nRun Trimmomatic\n\n\nFIXME: change these settings if required (examine FastQC reports)\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: QC and manipulation \n Trimmomatic\n.\n\n\nInput FASTQ file (R1/first of pair)\n: \nmutant_R1.fastq\n\n\nInput FASTQ file (R2/second of pair)\n: \nmutant_R2.fastq\n\n\nPerform initial ILLUMINACLIP step \n: \nYes\n\n\nAdapter sequences to use\n: FIXME\n\n\nHow accurate the match between the two \nadapter ligated\n reads must be for PE palindrome read alignment\n: 40\n\n\nHow accurate the match between any adapter etc. sequence must be against a read\n: 15\n\n\nleave the first \nTrimmomatic Operation\n as is\n\n\nclick on \n+ Insert Trimmomatic Operation\n\n\nSelect Trimmomatic operation to perform\n: \nCut bases off the start of a read, if below a threshold quality (LEADING)\n\n\nMinimum quality required to keep a base\n: 15\n\n\nclick on \n+ Insert Trimmomatic Operation\n\n\nSelect Trimmomatic operation to perform\n: \nCut bases off the end of a read, if below a threshold quality (TRAILING)\n\n\nMinimum quality required to keep a base\n: 15\n\n\nclick \nExecute\n\n\n\n\nFIXME: screenshot of these trimmomatic options selected\n\n\nExamine output\n\n\nTrimmomatic should produce 2 pairs files (1 left and 1 right hand end) and 1 or 2 single \u201corphaned reads\u201d files.\n\n\nThe output files are the ones you should use for assembly.\n\n\nThere are four output files, still in FASTQ format:\n\n\n\n\nR1 reads that have a pair in the R2 file\n\n\nR2 reads that have a pair in the R1 file\n\n\nR1 reads with no pair (R2 match was low quality: deleted)\n\n\nR2 reads with no pair (R1 match was low quality: deleted)\n\n\n\n\nExamine each file with the eye icon. Look for:\n\n\n\n\nNumber of reads orphaned by the trimming / cleanup process.\n\n\nNumber of pairs lost totally.\n\n\n\n\nWhat next?\n\n\nNext: use the output FASTQ files for Assembly, e.g. with \nSpades", 
            "title": "Trimmomatic in Galaxy"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#trimmomatic-on-galaxy", 
            "text": "", 
            "title": "Trimmomatic on Galaxy"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#introduction", 
            "text": "After checking your input sequence reads for quality (e.g. using FastQC) it might be necessary to trim the reads. Here we will use the Trimmomatic tool. For more inforamtion, see the Trimmomatic  webpage  and the  manual.", 
            "title": "Introduction"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   input sequence reads to Trimmomatic  trim using appropriate parameters, and  examine the output trimmed reads.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#start", 
            "text": "open your Galaxy instance  find your quality-checked Illumina sequence reads  e.g.  mutant_R1.fastq  and  mutant_R2.fastq  We want to trim the parts of the reads that are of low quality  based on the FastQC results, say we want to trim the reads like this:\n(FIXME: expand detail)  trim Illumina adapters  leading and trailing bases - trim if quality is below 15  sliding window - trim once average quality is below 20", 
            "title": "Start"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#trimmomatic-functions", 
            "text": "[from LSCC docs]    Adapter trimming   This function trims adapters, barcodes and other contaminants from the reads.  You need to supply a fasta file of possible adapter sequences, barcodes etc to trim. See Trimmomatic website for detailed instructions.  The default quality settings are sensible.  This should always be the first trimming step if it is used.     Sliding window trimming   This function uses a sliding window to measure average quality and trims accordingly.  The default quality parameters are sensible for this step.     Trailing bases quality trimming   This function trims bases from the end of a read if they drop below a quality threshold. e.g. If base 69 of 75 drops below the threshold, the read is cut to 68 bases.  Use FastQC report to decide whether this step is warranted and what quality value to use. A quality threshold value of 10-15 is a good starting point.     Leading bases quality trimming   This function works in a similar fashion to trailing bases trimming except it performs it at the start of the reads.  Use FastQC report to determine if this step is warranted. If the quality of bases is poor at the beginning of reads it might be necessary.     Minimum read length   Once all trimming steps are complete, this function makes sure that the reads are still longer than this value. If not, the read is removed from the file and its pair is put into the orphan file.  The most appropriate value for this parameter will depend on the FastQC report, specifically the length of the high quality section of the Per Base Sequence Quality graph.     Each read library should be trimmed separately with parameters dependent on their own FastQC reports.", 
            "title": "Trimmomatic functions"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#run-trimmomatic", 
            "text": "FIXME: change these settings if required (examine FastQC reports)   Go to  Tools   NGS Analysis   NGS: QC and manipulation   Trimmomatic .  Input FASTQ file (R1/first of pair) :  mutant_R1.fastq  Input FASTQ file (R2/second of pair) :  mutant_R2.fastq  Perform initial ILLUMINACLIP step  :  Yes  Adapter sequences to use : FIXME  How accurate the match between the two  adapter ligated  reads must be for PE palindrome read alignment : 40  How accurate the match between any adapter etc. sequence must be against a read : 15  leave the first  Trimmomatic Operation  as is  click on  + Insert Trimmomatic Operation  Select Trimmomatic operation to perform :  Cut bases off the start of a read, if below a threshold quality (LEADING)  Minimum quality required to keep a base : 15  click on  + Insert Trimmomatic Operation  Select Trimmomatic operation to perform :  Cut bases off the end of a read, if below a threshold quality (TRAILING)  Minimum quality required to keep a base : 15  click  Execute   FIXME: screenshot of these trimmomatic options selected", 
            "title": "Run Trimmomatic"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#examine-output", 
            "text": "Trimmomatic should produce 2 pairs files (1 left and 1 right hand end) and 1 or 2 single \u201corphaned reads\u201d files.  The output files are the ones you should use for assembly.  There are four output files, still in FASTQ format:   R1 reads that have a pair in the R2 file  R2 reads that have a pair in the R1 file  R1 reads with no pair (R2 match was low quality: deleted)  R2 reads with no pair (R1 match was low quality: deleted)   Examine each file with the eye icon. Look for:   Number of reads orphaned by the trimming / cleanup process.  Number of pairs lost totally.", 
            "title": "Examine output"
        }, 
        {
            "location": "/dna/qualitycontrol/trimmomatic/#what-next", 
            "text": "Next: use the output FASTQ files for Assembly, e.g. with  Spades", 
            "title": "What next?"
        }, 
        {
            "location": "/dna/denovo/pacbio/", 
            "text": "PacBio SMRT Portal\n\n\nThis tutorial will show you how to assemble a bacterial genome de novo, using the PacBio SMRT Portal.\n\n\nLink to PacBio analysis software\n\n\nPre-requisites\n\n\n\n\nmGVL instance with 16 cores (FIXME: will people have this - if not, note how they can request it)\n\n\nknowledge: de novo assembly\n\n\n\n\nStart\n\n\n\n\nOpen your mGVL dashboard.\n\n\nGo to Admin. There is a list of packages. Find SMRT Analysis. On the right, click on \nInstall\n.\n\n\nYou should see SMRT Portal as one of the instance services on your GVL dashboard.\n\n\nOpen up the SMRT portal web link (to the right) and register/log on.\n\n\n\n\nHow it works\n\n\n\n\nRS_HGAP_Assembly.3 Protocol\n\n\nFilters short and poor-quality reads.\n\n\nLarge insert (fragment) sizes =\n single pass long reads (but these have lower quality)\n\n\nand/or small insert (fragment) sizes =\n cut adapters and assemble subreads =\n Circular Consensus Sequence (CSS) reads (higher quality)\n\n\nPre-assembly e.g. with Canu\n\n\nPolishes assembly e.g. with Quiver (joins contigs/scaffolds?)\n\n\nCorrections\n\n\n\n\nInput\n\n\n\n\nChoose your data. (FIXME: e.g. on GenomeSpace?)\n\n\nGet the data you want to use onto your mGVL. (FIXME: explain how?)\n\n\nIn the SMRT Portal, go to \nDesign Job\n, the top left tab.\n\n\nGo to \nImport and Manage: Import SMRT cells: SMRT Cells\n. Work out where you put the data on your GVL, and make sure the file path is showing. If not, click \nAdd\n and list the file path to the data.\n\n\nClick on the file path and then \nScan\n to check for new data.\n\n\n\n\nRun\n\n\n\n\nGo back to the top tab \nDesign Job\n.\n\n\nGo to \nCreate New\n.\n\n\nAn \nAnalysis\n window should appear. Check the box next to \nDe novo assembly\n, then \nNext\n.\n\n\nUnder \nJob Name\n enter a name.\n\n\nUnder \nProtocols\n choose \nRS_HGAP_Assembly.3\n.\n\n\n\n\n\n\n\n\nThere is an ellipsis underneath \nProtocols\n - click on the ellipsis. This brings up the settings. Leave everything as is, except for: Click on \nAssembly\n. Change the \nGenome Size\n to an approximately correct size for the sample. Click \nOk\n.  \n\n\n\n\n\n\n\n\nIn the \nSMRT Cells Available\n window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.\n\n\n\n\n\n\n\n\nClick \nSave\n.\n\n\nNext to \nSave\n, click \nStart\n.\n\n\nThe \nMonitor Jobs\n window should open. As each step proceeds, new items will appear under the \nReports\n and \nData\n tabs on the left. Click on each of these items to see the details and graphs available, which will appear in the main pane. The default display in the main pane is \nOverview\n.\n\n\n\n\n\n\n\n\nFIXME: how long will it take for this example data.\n\n\n\n\nOutput\n\n\n\n\nThe current running jobs will be under the \nMonitor Jobs\n tab. Click on the job to see the reports and data.\n\n\nThe finished jobs will be under the \nView Data\n tab.\n\n\nA full ist of reports and terminology is here\n\n\nReports: General: Filtering\n: look at the table showing the pre-filter and post-filter information.\n\n\n\n\n\n\n\n\n\n\nFIXME: what are other graphs showing / why are there mapping/coverage graphs if a ref genome wasn\nt supplied?\n\n\n\n\n\n\nFIXME: what are the files under \nData\n for - further analyses later? where would these be saved if we want to use later.\n\n\n\n\n\n\nBAM and BAI files: view reads aligned to assembly (IGV)\n\n\n\n\n\n\nNext\n\n\n\n\nCheck assembly quality: for example, align to the same species in Mauve.\n\n\n\n\nLinks to more information:\n\n\n\n\nFinishing bacterial genomes", 
            "title": "PacBio SMRT portal"
        }, 
        {
            "location": "/dna/denovo/pacbio/#pacbio-smrt-portal", 
            "text": "This tutorial will show you how to assemble a bacterial genome de novo, using the PacBio SMRT Portal.  Link to PacBio analysis software", 
            "title": "PacBio SMRT Portal"
        }, 
        {
            "location": "/dna/denovo/pacbio/#pre-requisites", 
            "text": "mGVL instance with 16 cores (FIXME: will people have this - if not, note how they can request it)  knowledge: de novo assembly", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dna/denovo/pacbio/#start", 
            "text": "Open your mGVL dashboard.  Go to Admin. There is a list of packages. Find SMRT Analysis. On the right, click on  Install .  You should see SMRT Portal as one of the instance services on your GVL dashboard.  Open up the SMRT portal web link (to the right) and register/log on.", 
            "title": "Start"
        }, 
        {
            "location": "/dna/denovo/pacbio/#how-it-works", 
            "text": "RS_HGAP_Assembly.3 Protocol  Filters short and poor-quality reads.  Large insert (fragment) sizes =  single pass long reads (but these have lower quality)  and/or small insert (fragment) sizes =  cut adapters and assemble subreads =  Circular Consensus Sequence (CSS) reads (higher quality)  Pre-assembly e.g. with Canu  Polishes assembly e.g. with Quiver (joins contigs/scaffolds?)  Corrections", 
            "title": "How it works"
        }, 
        {
            "location": "/dna/denovo/pacbio/#input", 
            "text": "Choose your data. (FIXME: e.g. on GenomeSpace?)  Get the data you want to use onto your mGVL. (FIXME: explain how?)  In the SMRT Portal, go to  Design Job , the top left tab.  Go to  Import and Manage: Import SMRT cells: SMRT Cells . Work out where you put the data on your GVL, and make sure the file path is showing. If not, click  Add  and list the file path to the data.  Click on the file path and then  Scan  to check for new data.", 
            "title": "Input"
        }, 
        {
            "location": "/dna/denovo/pacbio/#run", 
            "text": "Go back to the top tab  Design Job .  Go to  Create New .  An  Analysis  window should appear. Check the box next to  De novo assembly , then  Next .  Under  Job Name  enter a name.  Under  Protocols  choose  RS_HGAP_Assembly.3 .     There is an ellipsis underneath  Protocols  - click on the ellipsis. This brings up the settings. Leave everything as is, except for: Click on  Assembly . Change the  Genome Size  to an approximately correct size for the sample. Click  Ok .       In the  SMRT Cells Available  window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.     Click  Save .  Next to  Save , click  Start .  The  Monitor Jobs  window should open. As each step proceeds, new items will appear under the  Reports  and  Data  tabs on the left. Click on each of these items to see the details and graphs available, which will appear in the main pane. The default display in the main pane is  Overview .     FIXME: how long will it take for this example data.", 
            "title": "Run"
        }, 
        {
            "location": "/dna/denovo/pacbio/#output", 
            "text": "The current running jobs will be under the  Monitor Jobs  tab. Click on the job to see the reports and data.  The finished jobs will be under the  View Data  tab.  A full ist of reports and terminology is here  Reports: General: Filtering : look at the table showing the pre-filter and post-filter information.      FIXME: what are other graphs showing / why are there mapping/coverage graphs if a ref genome wasn t supplied?    FIXME: what are the files under  Data  for - further analyses later? where would these be saved if we want to use later.    BAM and BAI files: view reads aligned to assembly (IGV)", 
            "title": "Output"
        }, 
        {
            "location": "/dna/denovo/pacbio/#next", 
            "text": "Check assembly quality: for example, align to the same species in Mauve.", 
            "title": "Next"
        }, 
        {
            "location": "/dna/denovo/pacbio/#links-to-more-information", 
            "text": "Finishing bacterial genomes", 
            "title": "Links to more information:"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/", 
            "text": "Assembly with Spades in Galaxy\n\n\nFIXME: This tutorial includes the Workshop 2a \nAssembly with Spades\n but also some extra info:\n\n\n\n\nsection: Pre-requisites\n\n\nsection: How does Spades work  \n\n\nmore detail on output files\n\n\nsection: Filter output\n\n\nsection: questions  \n\n\n\n\nBackground\n\n\nSpades is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this \nlink\n. A protocol for assembling with Velvet (another \nde novo\n assembler) is available \nhere\n.\n\n\nIn this activity, we will perform a \nde novo\n assembly of a short read set (from an Illumina sequencer) using the Spades assembler. The output from Spades that we are interested in is a multifasta file that contains the draft genome sequence.\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome.\n\n\nWe have a closed, annotated genome sequence for a closely related \nwildtype\n strain.\n\n\nThe whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\nThe reads are paired-end\n\n\nEach read is 150 bases (before trimming)\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nimport data into Galaxy  \n\n\nview the files\n\n\nevaluate the read quality\n\n\nassemble the reads using Spades, and\n\n\nexamine the output assembly.\n\n\n\n\nPre-requisites\n\n\n\n\nGalaxy\n\n\nde novo assembly\n\n\nQC\n\n\nTrimming\n\n\n\n\nLogin to Galaxy\n\n\n\n\nGo to this Galaxy address: \nhttp://43.240.98.1/galaxy\n  (FIXME: or alternative)\n\n\nRemind me how to logon.\n\nFIXME: note this contains the same galaxy address as above - change?\n\n\n\n\nImport data\n\n\n\n\nClick on the \nAnalyze Data\n menu at the top of the page.    \n\n\nClick on the \nHistory options\n button the \n on the top right of the history pane.\n\n\nClick \nImport from File\n (at the bottom of the list).  \n\n\nA new page will appear with a text box for the URL of the history to import.  \n\n\nCopy the following URL into the text box: \nhttp://43.240.98.1/public/dieter/Galaxy-History-Colombiaworkshopstart.tar.gz\n  \n\n\nClick \nSubmit\n.  \n\n\nGalaxy will download the data files from the internet and will be available as an additional history (takes about one minute).  \n\n\nTo view this new history, click the \nView all histories\n button\n (top right of the history pane).  \n\n\nIf the history has finished downloading it will appear as \nimported from archive: Colombia_workshop_start\n\n\nClick on the \n button above the \nimported from archive:Colombia_workshop_start\n then the \n button.\n\n\nYou should now have four files in the history pane as follows:\n\n\n\n\n\n\nView files\n\n\nAll the files are text files.\n\n\n\n\nmutant_R1.fastq\n and \nmutant_R2.fastq\n: a paired-end read set  \n\n\nwildtype.fna\n: a file that contains the genome sequence of the wildtype strain in fasta format (a header line, then the nucleotide sequence of the genome)\n\n\nwildtype.gff\n: a file that contains the genome sequence of the wildtype strain in general feature format. (a list of features - one feature per line, then the nucleotide sequence of the genome)\n\n\n\n\nLook at the contents of these files\n\n\n\n\nClick on the View Data button (the \n) next to each of the files in turn.\n\n\nBrief Discussion about the GFF format (FIXME: add?)\n\n\n\n\n\n\nEvaluate the input reads\n\n\nQuestions you might ask about your input reads include:\n\n\n\n\nHow good is my read set?\n\n\nDo I need to ask for a new sequencing run?  \n\n\nIs it suitable for the analysis I need to do?\n\n\n\n\nWe will evaluate the input reads using the FastQC tool.\n\n\n\n\nThis runs a standard series of tests on your read set and returns a relatively easy to interpret report.\n\n\nWe will use the FASTQC tool in Galaxy to evaluate the quality of one of our fastq files.\n\n\nGo to \nTools \n NGS:Analysis \n NGS: QC and Manipulation \n FastQC\n\n\nSelect \nmutant_R1.fastq\n\n\nExecute\n\n\nOnce finished, examine the output called \nFastQC on data1:webpage\n (Hint:\n). It has a summary at the top of the page and a number of graphs.\n\n\n\n\nSome of the important outputs of FastQC for our purposes are:\n\n\n\n\nBasic Statistics: Sequence length\n: will be important in setting maximum k-mer size value for assembly\n\n\nBasic Statistics: Encoding\n: Quality encoding type: important for quality trimming software\n\n\nBasic Statistics: % GC\n: high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.\n\n\nBasic Statistics: Total sequences\n: Total number of reads: gives you an idea of coverage.\n\n\nPer base sequence quality\n: Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.\n\n\nPer base N content\n: Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.\n\n\nKmer content\n: Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc.\n\n\n\n\nAlthough we have warnings for two outputs (per base sequence content; Kmer content), we can ignore these for now. For a fuller discussion of FastQC outputs and warnings, see the \nFastQC website link\n, including the section on each of the output \nreports\n, and examples of \ngood\n and \nbad\n Illumina data. We won\u2019t be doing anything to these data to clean it up as there isn\u2019t much need. Therefore we will get on with the assembly!\n\n\nHow does Spades work?\n\n\n\n\n\n\nAs with several other de novo assembly programs (e.g. Velvet) Spades uses an algorithm based on \nde Bruijn graphs.\n Such graphs use sub-lengths of sequence reads to build an overall genome assembly. The span of the sub-length is called a k-mer, where \nk\n is the number of nucleotides (e.g. k=21). The user chooses three values of k and Spades makes three assemblies based on these.\n\n\n\n\n\n\nFor the first value of k, each read is broken into as many fragments as possible. For example, if the input read is 22 nucleotides long, and the chosen value of k is 21, then there are two possible fragments (positions 1-21 and 2-22).\n\n\n\n\n\n\nOne randomly-chosen fragment becomes the first node on the de Bruijn graph.\n\n\n\n\n\n\nA second fragment is connected to this node if it overlaps.\n\n\n\n\n\n\nRepeat until all fragments are connected. Output \n de Bruijn graph.\n\n\n\n\n\n\nFind a connected pathway through this graph. Output \n a pathway (sequence) known as a contig. Because of poor or incorrect sequencing, not all the fragments can be joined together. There will be several de Bruijn graphs and so several contigs, usually of different sizes.\n\n\n\n\n\n\nRepeat these steps for a further two values of k (e.g. k = 33, k = 55). Output \n Three (sets of) contigs.\n\n\n\n\n\n\nMerge the three (sets of) contigs to get one. Output \n one set of contigs.\n\n\n\n\n\n\nFor paired-end reads (as in this tutorial), the two reads are sequenced from each end of a longer DNA fragment. The middle part of the fragment is not sequenced, but information about the distance between the reads can be used by Spades to join contigs into larger sequences, called scaffolds. Output \n one set of scaffolds.\n\n\n\n\n\n\nTo fix any errors map the original sequence reads onto the scaffolds with the program BWA. Output \n assembled genome.\n\n\n\n\n\n\nAssemble reads with Spades\n\n\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant fastq reads into long contiguous sequences (in fasta format.)\n\n\n\n\n\n\nSpades produces both contigs and scaffolds. Ask your demonstrator if you would like to know the difference between contigs and scaffolds.\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n spades\n\n\n\n\n\n\nSet the following parameters:\n\n\n\n\nRun only Assembly\n: \nYes\n  \n\n\nKmers to use separated by commas:\n \n33,55,91\n  no spaces  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\nFiles \n Forward reads:\n \nmutant_R1.fastq\n  \n\n\nFiles \n Reverse reads:\n \nmutant_R2.fastq\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running Spades on the reads for you.\n\n\nWhen it is finished, you will have five new files in your history.  \n\n\ncontig stats\n: There are x contigs. Look at the variation in length and coverage. A short contig with high coverage could be a result of contamination, a collapsed repeat, or a plasmid.\n\n\ncontigs\n: Each contig is listed, followed by its sequence in fasta format.\n\n\nscaffold stats\n: There are x scaffolds.\n\n\nscaffolds\n: Each scaffold is listed, followed by its sequence in fasta format.\n\n\nlog\n: The specific actions performed in the analysis.\n\n\nClick on the View Data button \n on each of the files.\n\n\nNote that the short reads have been assembled into much longer contigs.\n\n\n(However, in this case, the contigs have not been assembled into larger scaffolds.)\n\n\nThe stats files will give you the length of each of the contigs.\n\n\n\n\nFilter output\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n Filter SPAdes output\n.\n\n\nThis is a quick way to discard contigs that are too short (e.g., they might be contamination) or contigs that do not have enough coverage (e.g., they might be too unreliable).\n\n\n\n\nUnder \nSequences\n, choose the contigs fasta file.\n\n\nUnder \nContig stats\n choose the contigs stats file. Change the cut-off values for length and coverage or leave them as they are.\n\n\nFor \nSave filtered-out sequences?\n click \nYes\n.\n\n\nClick \nExecute\n. A new fasta file with only the filtered sequences will be saved in the right-side history pane.\n\n\n\n\nQuestions\n\n\n \n\nHow does SPAdes differ from other genome assembly programs?\n\nIt uses multiple values of k in de Bruijn graphs. Larger fragment sizes will more accurately position sections of duplicated DNA (repeats), but these larger fragments will only overlap well in densely-sequenced (high-coverage) areas of the genome. Because bacterial genomes may have low-coverage regions, using smaller fragments can increase the potential for overlaps (joins) in these low-coverage regions. Using a range of fragment sizes will therefore get the benefit from both approaches. More information \nhere\n.\n\n\n \n\nHow do I choose values of k?  \n\nThe k values need to be odd numbers, and shorter than the read lengths.  A good strategy could be to choose some that are small, medium and large. e.g. if the read is 150 nucleotides, k values could be 33, 55, 91. There is no absolute rule; rather, the aim is to get a good spread of k values across the read length. \n\n\n \n\nWhat can I do with my assembled genome?\n\nThis tutorial used a subset of a real dataset, so is not a complete genome (is it?). You could re-try it with short reads from a whole genome, at NCBI SRA. You can [annotate] (describe) the genomic features such as genes or [compare] it to other genomes to see variation in structure.  \n\n\nWhat Next?\n\n\nAnnotate the genome, e.g. with \nProkka\n.", 
            "title": "Galaxy-Spades"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#assembly-with-spades-in-galaxy", 
            "text": "FIXME: This tutorial includes the Workshop 2a  Assembly with Spades  but also some extra info:   section: Pre-requisites  section: How does Spades work    more detail on output files  section: Filter output  section: questions", 
            "title": "Assembly with Spades in Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#background", 
            "text": "Spades is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this  link . A protocol for assembling with Velvet (another  de novo  assembler) is available  here .  In this activity, we will perform a  de novo  assembly of a short read set (from an Illumina sequencer) using the Spades assembler. The output from Spades that we are interested in is a multifasta file that contains the draft genome sequence.  The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome.  We have a closed, annotated genome sequence for a closely related  wildtype  strain.  The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.   The reads are paired-end  Each read is 150 bases (before trimming)  The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).", 
            "title": "Background"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   import data into Galaxy    view the files  evaluate the read quality  assemble the reads using Spades, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#pre-requisites", 
            "text": "Galaxy  de novo assembly  QC  Trimming", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#login-to-galaxy", 
            "text": "Go to this Galaxy address:  http://43.240.98.1/galaxy   (FIXME: or alternative)  Remind me how to logon. \nFIXME: note this contains the same galaxy address as above - change?", 
            "title": "Login to Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#import-data", 
            "text": "Click on the  Analyze Data  menu at the top of the page.      Click on the  History options  button the   on the top right of the history pane.  Click  Import from File  (at the bottom of the list).    A new page will appear with a text box for the URL of the history to import.    Copy the following URL into the text box:  http://43.240.98.1/public/dieter/Galaxy-History-Colombiaworkshopstart.tar.gz     Click  Submit .    Galaxy will download the data files from the internet and will be available as an additional history (takes about one minute).    To view this new history, click the  View all histories  button  (top right of the history pane).    If the history has finished downloading it will appear as  imported from archive: Colombia_workshop_start  Click on the   button above the  imported from archive:Colombia_workshop_start  then the   button.  You should now have four files in the history pane as follows:", 
            "title": "Import data"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#view-files", 
            "text": "All the files are text files.   mutant_R1.fastq  and  mutant_R2.fastq : a paired-end read set    wildtype.fna : a file that contains the genome sequence of the wildtype strain in fasta format (a header line, then the nucleotide sequence of the genome)  wildtype.gff : a file that contains the genome sequence of the wildtype strain in general feature format. (a list of features - one feature per line, then the nucleotide sequence of the genome)   Look at the contents of these files   Click on the View Data button (the  ) next to each of the files in turn.  Brief Discussion about the GFF format (FIXME: add?)", 
            "title": "View files"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#evaluate-the-input-reads", 
            "text": "Questions you might ask about your input reads include:   How good is my read set?  Do I need to ask for a new sequencing run?    Is it suitable for the analysis I need to do?   We will evaluate the input reads using the FastQC tool.   This runs a standard series of tests on your read set and returns a relatively easy to interpret report.  We will use the FASTQC tool in Galaxy to evaluate the quality of one of our fastq files.  Go to  Tools   NGS:Analysis   NGS: QC and Manipulation   FastQC  Select  mutant_R1.fastq  Execute  Once finished, examine the output called  FastQC on data1:webpage  (Hint: ). It has a summary at the top of the page and a number of graphs.   Some of the important outputs of FastQC for our purposes are:   Basic Statistics: Sequence length : will be important in setting maximum k-mer size value for assembly  Basic Statistics: Encoding : Quality encoding type: important for quality trimming software  Basic Statistics: % GC : high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.  Basic Statistics: Total sequences : Total number of reads: gives you an idea of coverage.  Per base sequence quality : Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run.  Per base N content : Presence of large numbers of Ns in reads: may point to poor quality sequencing run. You would need to trim these reads to remove Ns.  Kmer content : Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc.   Although we have warnings for two outputs (per base sequence content; Kmer content), we can ignore these for now. For a fuller discussion of FastQC outputs and warnings, see the  FastQC website link , including the section on each of the output  reports , and examples of  good  and  bad  Illumina data. We won\u2019t be doing anything to these data to clean it up as there isn\u2019t much need. Therefore we will get on with the assembly!", 
            "title": "Evaluate the input reads"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#how-does-spades-work", 
            "text": "As with several other de novo assembly programs (e.g. Velvet) Spades uses an algorithm based on  de Bruijn graphs.  Such graphs use sub-lengths of sequence reads to build an overall genome assembly. The span of the sub-length is called a k-mer, where  k  is the number of nucleotides (e.g. k=21). The user chooses three values of k and Spades makes three assemblies based on these.    For the first value of k, each read is broken into as many fragments as possible. For example, if the input read is 22 nucleotides long, and the chosen value of k is 21, then there are two possible fragments (positions 1-21 and 2-22).    One randomly-chosen fragment becomes the first node on the de Bruijn graph.    A second fragment is connected to this node if it overlaps.    Repeat until all fragments are connected. Output   de Bruijn graph.    Find a connected pathway through this graph. Output   a pathway (sequence) known as a contig. Because of poor or incorrect sequencing, not all the fragments can be joined together. There will be several de Bruijn graphs and so several contigs, usually of different sizes.    Repeat these steps for a further two values of k (e.g. k = 33, k = 55). Output   Three (sets of) contigs.    Merge the three (sets of) contigs to get one. Output   one set of contigs.    For paired-end reads (as in this tutorial), the two reads are sequenced from each end of a longer DNA fragment. The middle part of the fragment is not sequenced, but information about the distance between the reads can be used by Spades to join contigs into larger sequences, called scaffolds. Output   one set of scaffolds.    To fix any errors map the original sequence reads onto the scaffolds with the program BWA. Output   assembled genome.", 
            "title": "How does Spades work?"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#assemble-reads-with-spades", 
            "text": "We will perform a  de novo  assembly of the mutant fastq reads into long contiguous sequences (in fasta format.)    Spades produces both contigs and scaffolds. Ask your demonstrator if you would like to know the difference between contigs and scaffolds.    Go to  Tools   NGS Analysis   NGS: Assembly   spades    Set the following parameters:   Run only Assembly :  Yes     Kmers to use separated by commas:   33,55,91   no spaces    Coverage cutoff:   auto     Files   Forward reads:   mutant_R1.fastq     Files   Reverse reads:   mutant_R2.fastq        Your tool interface should look like this:      Click  Execute", 
            "title": "Assemble reads with Spades"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#examine-the-output", 
            "text": "Galaxy is now running Spades on the reads for you.  When it is finished, you will have five new files in your history.    contig stats : There are x contigs. Look at the variation in length and coverage. A short contig with high coverage could be a result of contamination, a collapsed repeat, or a plasmid.  contigs : Each contig is listed, followed by its sequence in fasta format.  scaffold stats : There are x scaffolds.  scaffolds : Each scaffold is listed, followed by its sequence in fasta format.  log : The specific actions performed in the analysis.  Click on the View Data button   on each of the files.  Note that the short reads have been assembled into much longer contigs.  (However, in this case, the contigs have not been assembled into larger scaffolds.)  The stats files will give you the length of each of the contigs.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#filter-output", 
            "text": "Go to  Tools   NGS Analysis   NGS: Assembly   Filter SPAdes output .  This is a quick way to discard contigs that are too short (e.g., they might be contamination) or contigs that do not have enough coverage (e.g., they might be too unreliable).   Under  Sequences , choose the contigs fasta file.  Under  Contig stats  choose the contigs stats file. Change the cut-off values for length and coverage or leave them as they are.  For  Save filtered-out sequences?  click  Yes .  Click  Execute . A new fasta file with only the filtered sequences will be saved in the right-side history pane.", 
            "title": "Filter output"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#questions", 
            "text": "How does SPAdes differ from other genome assembly programs? \nIt uses multiple values of k in de Bruijn graphs. Larger fragment sizes will more accurately position sections of duplicated DNA (repeats), but these larger fragments will only overlap well in densely-sequenced (high-coverage) areas of the genome. Because bacterial genomes may have low-coverage regions, using smaller fragments can increase the potential for overlaps (joins) in these low-coverage regions. Using a range of fragment sizes will therefore get the benefit from both approaches. More information  here .    \nHow do I choose values of k?   \nThe k values need to be odd numbers, and shorter than the read lengths.  A good strategy could be to choose some that are small, medium and large. e.g. if the read is 150 nucleotides, k values could be 33, 55, 91. There is no absolute rule; rather, the aim is to get a good spread of k values across the read length.     \nWhat can I do with my assembled genome? \nThis tutorial used a subset of a real dataset, so is not a complete genome (is it?). You could re-try it with short reads from a whole genome, at NCBI SRA. You can [annotate] (describe) the genomic features such as genes or [compare] it to other genomes to see variation in structure.", 
            "title": "Questions"
        }, 
        {
            "location": "/dna/denovo/galaxy-spades/#what-next", 
            "text": "Annotate the genome, e.g. with  Prokka .", 
            "title": "What Next?"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/", 
            "text": "Galaxy - Velvet\n\n\nModified from LSCC tutorial by \nSimon Gladman\n - VLSCI\n\n\nTutorial Overview\n\n\nIn this tutorial we cover the concepts of Microbial de novo assembly using a very small synthetic dataset from a well studied organism.\n\n\nBackground\n\n\nWhere is the data in this tutorial from?\n\n\nThe data for this tutorial is from a whole genome sequencing experiment of a multi-drug resistant strain of the bacterium \nStaphylococcus aureus\n. The DNA was sequenced using an Illumina GAII sequencing machine. The data we are going to use consists of about 4 million x 75 base-pair, paired end reads (two FASTQ read files, one for each end of a DNA fragment.) The data was downloaded from the \nNCBI Short Read Archive (SRA)\n (http://www.ncbi.nlm.nih.gov/sra/). The specific sample is a public dataset published in April 2012 with SRA accession number ERR048396.\n\n\nWe will also use a FASTA file containing the sequences of the Illumina adapters used in the sequencing process. It is desirable to remove these as they are artificial sequences and not part of the bacterium that was sequenced.\n\n\nWe will use software called \nVelvet\n (Zerbino et al 2008) for the main de novo assembly, as well as some other peripheral software for pre- and post-processing of the data. Details of these can be found in the background document linked above.\n\n\nThe protocol:\n\n\nWe are performing a de novo assembly of the read data into contigs and then into scaffolds (appropriately positioned contigs loosely linked together). We firstly need to check the quality of the input data as this will help us choose the most appropriate range of input parameters for the assembly and will guide us on an appropriate quality trimming/cleanup strategy. We will then use an iterative method to assemble the reads using the \nVelvet Optimiser\n (a program that performs lots of Velvet assemblies searching for an optimum outcome.) Once this is complete we will obtain summary statistics on the final results (contigs) of the assembly.\n\n\nMore information about this protocol at the end of this tutorial.\n\n\nThe protocol in a nutshell:\n\n\nInput:\n Raw reads from sequencer run on microbial DNA sample.\n\n\nOutput:\n File of assembled scaffolds/contigs and associated information.\n\n\nInput data\n\n\n\n\nOn the Galaxy tools panel, click on \nGet data -\n Upload File\n.\n\n\nClick on the \nPaste/Fetch Data\n button.\n\n\nPaste the URL: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/ERR048396_1.fastq.gz\n into the text box. Change the type to \nfastqsanger\n (Not \nfastqcsanger\n).\n\n\nClick on the \nPaste/Fetch Data\n button again.\n\n\nPaste the URL: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/ERR048396_2.fastq.gz\n into the text box and change it\ns type to \nfastqsanger\n as well.\n\n\nRepeat the process for the last URL: \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/illumina_adapters.fna\n , but make it\ns type \nfasta\n\n\nClick on the \nStart\n button. Once all of the uploads are at 100%, click on the \nClose\n button.\n\n\nWhen the files have finished uploading, rename them to \u2018ERR048396_1.fastq\u2019, \u2018ERR048396_2.fastq\u2019 and \u2018illumina_adapters.fna\u2019 respectively by clicking on the \n icon to the top right of the file name in the right hand Galaxy panel (the history panel)\n\n\n\n\nYou should now have the following files in your Galaxy history:\n\n\n\n\nERR048396_1.fastq\n - forward reads in fastq format\n\n\nERR048396_2.fastq\n - reverse reads in fastq format\n\n\nillumina_adapters.fa\n - Illumina adapter sequences in fasta format\n\n\n\n\nClick on the \n icon to the top right of each fastq file to view the first part of the file\n\n\nSection 1: Quality control\n\n\nThe basic process here is to collect statistics about the quality of the reads in the sample FASTQ readsets. We will then evaluate their quality and choose an appropriate regime for quality filtering using Trimmomatic (a FASTQ read quality trimmer.)\n\n\nRun FastQC on both input read files\n\n\n\n\nFrom the tools menu in the left hand panel of Galaxy, select \nNGS QC and manipulation \n FastQC: Comprehensive QC\n (down the bottom of this category) and run with these parameters:\n\n\nFASTQ reads\n: \nERR048396_1.fastq\n\n\nUse default for other fields\n\n\n\n\n\n\nClick \nExecute\n\n\nNow repeat the above process on the second read file: \nERR048396_2.fastq\n\n\n\n\nIt is important to do both read files as the quality can be very different between them.\n\n\nFigure 1: Screenshot of FastQC interface in Galaxy\n\n\n\n\nExamine the FastQC output\n\n\nYou should have two output objects from the first step:\n\n\n\n\nFastQC_ERR048396_1.fastqc.html\n\n\nFastQC_ERR048396_2.fastqc.html\n\n\n\n\nThese are a html outputs which show the results of all of the tests FastQC performed on the read files.\n\n\n\n\nClick on the \n icon of each of these objects in turn to see the FastQC output.\n\n\n\n\nThe main parts of the output to evaluate are:\n\n\n\n\nBasic statistics. This section tells us that the ASCII quality encoding format used was Sanger/Illumina 1.9 and the reads are length 75 and the percent GC content of the entire file is 35%.\n\n\nPer base sequence quality. In the plot you should see that most of the early bases are up around the \n32\n mark and then increase to 38-40, which is very high quality; The spread of quality values for the last few bases increases and some of the outliers have quality scores of less than 30. This is a very good quality dataset. 20 is often used as a cutoff for reliable quality.\n\n\n\n\nFigure 2: Screenshot of FastQC output in Galaxy\n\n\n\n\nQuality trim the reads using Trimmomatic.\n\n\n\n\n\n\nFrom the tools menu in the left hand panel of Galaxy, select \nNGS QC and manipulation \n Trimmomatic\n and run with these parameters (only the non-default selections are listed here):\n\n\n\n\nInput FASTQ file (R1/first of pair)\n: \nERR048396_1.fastq\n\n\nInput FASTQ file (R2/second of pair)\n: \nERR048396_2.fastq\n\n\nPerform initial ILLUMINACLIP step?\n: \nYes\n\n\nAdapter sequences to use\n: \nTruSeq3 (additional seqs) (paired end, for MiSeq and HiSeq)\n\n\nHow accurate \n read alignment\n: \n40\n\n\nHow accurate \n against a read\n: \n15\n\n\nWe will use the default settings for the SLIDING_WINDOW operation but we need to add a few more Trimmomatic operations.\n\n\nClick \nInsert Trimmomatic Operation\n\n\nAdd \nCut bases \n (LEADING)\n\n\nMinimum quality required to keep a base\n: \n15\n\n\n\n\n\n\nRepeat the \nInsert Trimmomatic Operation\n for:\n\n\nTrim trailing bases, minimum quality: \n15\n\n\nMinimum length read: \n35\n\n\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n      \n\n\n\n\n\n\nFigure 3: Screenshot of Trimmomatic inputs in Galaxy\n\n\n\n\nExamine the Trimmomatic output FastQ files.\n\n\nYou should have 4 new objects in your history from the output of Trimmomatic:\n\n\n\n\nTrimmomatic on data 2 and data 1 (R1 Paired)\n\n\nTrimmomatic on data 2 and data 1 (R1 Unpaired)\n\n\nTrimmomatic on data 2 and data 1 (R2 Paired)\n\n\nTrimmomatic on data 2 and data 1 (R2 Unpaired)\n\n\n\n\nClick on the \n on one of the objects to look at its contents. You\u2019ll notice that not all of the reads are the same length now, as they have had the illumina adapters cut out of them and they\u2019ve been quality trimmed.\n\n\n\n\nSection 2: Assemble reads into contigs with Velvet and the Velvet Optimiser\n\n\nThe aim here is to assemble the trimmed reads into contigs/scaffolds using Velvet and the Velvet Optimiser.\n\n\nWe will use a single tool, Velvet Optimiser, which takes the trimmed reads from Trimmomatic and performs numerous Velvet assemblies to find the best one. We need to add the reads in two separate libraries. One for the still paired reads and the other for the singleton reads orphaned from their pairs by the trimming process.\n\n\nClick here for a more detailed explanation of Velvet assemblies and the Velvet Optimiser\n\n\nDe novo assembly of the reads into contigs\n\n\n\n\nFrom the tools menu in the left hand panel of Galaxy, select \nNGS: Assembly -\n Velvet Optimiser\n and run with these parameters (only the non-default selections are listed here):\n\n\nStart k-mer value\n: \n55\n\n\nEnd k-mer value\n: \n69\n\n\nIn the input files section:\n\n\nSelect first set of reads\n: \nTrimmomatic on data 2 and data 1 (R1 paired)\n\n\nSelect second set of reads\n: \nTrimmomatic on data 2 and data 1 (R2 paired)\n\n\n\n\n\n\nClick the \nInsert Input Files\n button and add the following:\n\n\nSingle or paired end reads\n: \nSingle\n\n\nSelect the reads\n: \nTrimmomatic on data 2 and data 1 (R1 unpaired)\n\n\n\n\n\n\nRepeat the above process to add the other unpaired read set \nTrimmomatic on data 2 and data 1 (R2 unpaired)\n as well.\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nFigure 4: Screenshot of Velvet Optimiser inputs in Galaxy\n\n\n\n\nExamine assembly output\n\n\nOnce step 1 is complete, you should now have 2 new objects in your history:\n\n \nVelvetOptimiser on data 9, data 7, and others: Contigs\n\n\n \nVelvetOptimiser on data 9, data 7, and others: Contig Stats\n\n\nClick on the \n icon of the various objects.\n\n\n\n\n\n\nContigs: You\u2019ll see the first MB of the file. Note that the contigs are named NODE_XX_length_XXXX_cov_XXX.XXX. This information tells you how long (in k-mer length) each contig is and what it\u2019s average k-mer coverage is. (See detailed explanation of Velvet and Velvet Optimiser for explanation of k-mer coverage and k-mer length.)\n\n\n\n\n\n\nContig stats: This shows a table of the contigs and their k-mer coverages and which read library contributed to the coverage. It is interesting to note that some of them have much higher coverage than the average. These are most likely to be repeated contigs. (Things like ribosomal RNA and IS elements.)\n\n\n\n\n\n\nFigure 5: Screenshot of assembled contigs (a) and contig stats (b)\n\n\na\n\n\n\n\nb\n\n\n\n\nCalculate some statistics on the assembled contigs\n\n\n\n\nFrom the tools menu in the left hand panel of Galaxy, select \nFASTA Manipulation -\n Fasta Statistics\n and run with these parameters:\n\n\nFasta or multifasta file\n: \nVelvet Optimiser \n Contigs\n\n\n\n\n\n\nClick \nExecute\n\n\nExamine the Fasta Stats output\n\n\n\n\nYou should now have one more object in your history: \nFasta Statistics on data 10: Fasta summary stats\n\n\nClick on the \n icon next to this object and have a look at the output. You\u2019ll see a statistical summary of the contigs including various length stats, the % GC content, the n50 as well as the number of contigs and the number of N bases contained in them.\n\n\n\n\nSection 3: Extension.\n\n\nExamine the contig coverage depth and blast a high coverage contig against a protein database.\n\n\nExamine the contig coverage depth.\n\n\nLook at the Contig Stats data (Velvet Optimiser vlsci on data 8, data 9, and data 7: Contig stats) by clicking on the \n icon. Note that column 2 contig length (lgth), shows a number of very short contigs (some are length 1).\n\n\n\n\nWe can easily filter out these short contigs from this information list by using the \nFilter and Sort -\n Filter tool.\n\n\nSet the following:\n\n\nFilter\n: \nVelvet Optimiser on data 8, data 7 and others: Contig stats\n\n\nWith the following condition\n: \nc2 \n 100\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nThe new data object in the history is called: \nFilter on data 11\n.\n\n\nClick on its \n icon to view it. Look through the list taking note of the coverages. Note that the average of the coverages (column 6) seems to be somewhere between 16 and 32.  There are a lot of contigs with coverage 16. We could say that these contigs only appear once in the genome of the bacteria. Therefore, contigs with double this coverage would appear twice. Note that some of the coverages are \n400! These contigs will appear in the genome more than 20 times!\n\n\nLets have a look at one of these contigs and see if we can find out what it is.\n\n\nExtract a single sequence from the contigs file.\n\n\nNote the contig number (column 1 in the Contig stats file) of a contig with a coverage of over 300. There should be a few of them. We need to extract the fasta sequence of this contig from the contigs multifasta so we can see it more easily.\n\n\nTo do this we will use the tool:\n\n\n\n\nFasta manipulation -\n Fasta Extract Sequence\n\n\nSet the following:\n\n\nFasta or multifasta file\n: \nVelvet Optimiser \n : Contigs\n\n\nSequence ID (or partial): \nNODE_1_\n (for example)\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nThe new data object in the history is called: \nFasta Extract Sequence on data 10: Fasta\n.\n\n\nClick on its \n icon to view it. It is a single sequence in fasta format.\n\n\nBlast sequence to determine what it contains.\n\n\nWe want to find out what this contig is or what kind of coding sequence (if any) it contains. So we will blast the sequence using the NCBI blast website. (External to Galaxy). To do this:\n\n\n\n\nBring up the sequence of the contig into the main window of the browser by clicking on the \n icon if it isn\u2019t already.\n\n\nSelect the entire sequence by clicking and dragging with the mouse or by pressing ctrl-a in the browser.\n\n\nCopy the selected sequence to the clipboard.\n\n\nOpen a new tab of your browser and point it to: http://blast.ncbi.nlm.nih.gov/Blast.cgi\n\n\nUnder the BASIC BLAST section, click \u201cblastx\u201d.\n\n\nPaste the sequence into the large text box labelled: Enter Accession number(s), gi(s) or FASTA sequence(s).\n\n\nChange the Genetic code to: Bacteria and Archaea (11)\n\n\nClick the button labelled: BLAST\n\n\n\n\nAfter a while the website will present a report of the blast run. Note that the sequence we blasted (if you chose NODE_1) is identical to part of a transposase gene (IS256) from a similar Staphylococcus aureus bacteria. These transposases occur frequently as repeats in bacterial genomes and so we shouldn\u2019t be surprised at its very high coverage.\n\n\nFigure 6: Screenshot of the output from the NCBI Blast website\n\n\n\n\n\n\nDe novo assembly with Velvet and the Velvet Optimiser.\n\n\nVelvet\n\n\nVelvet is software to perform dna assembly from short reads by manipulating de Bruijn graphs. It is capable of forming long contigs (n50 of in excess of 150kb) from paired end short reads. It has several input parameters for controlling the structure of the de Bruijn graph and these must be set optimally to get the best assembly possible. Velvet can read Fasta, FastQ, sam or bam files. However, it ignores any quality scores and simply relies on sequencing depth to resolve errors. The Velvet Optimiser software performs many Velvet assemblies with various parameter sets and searches for the optimal assembly automatically.\n\n\nde Bruijn graphs\n\n\nA de Bruijn graph is a directed graph which represents overlaps between sequences of symbols. The size of the sequence contained in the nodes of the graph is called the word-length or k-mer size. In Figure 2, the word length is 3. The two symbols are 1 and 0. Each node in the graph has the last two symbols of the previous node and 1 new symbol. Sequences of symbols can be produced by traversing the graph and adding the \u201cnew\u201d symbol to the growing sequence.\n\n\nFigure 2: A de Bruijn graph of word length 3 for the symbols 1 and 0.\n\n\n\n\nFrom: https://cameroncounts.wordpress.com/2015/02/28/1247/\n\n\nVelvet constructs a de Bruijn graph of the reads. It has 4 symbols (A, C, G and T - N\u2019s are converted to A\u2019s) The word length (or k-mer size) is one of Velvet\u2019s prime parameters.\n\n\nVelvet is not the only assembly software that works in this manner. Euler, Edena and SOAP de novo are examples of others.\n\n\nThe Velvet algorithm\n\n\nStep 1: Hashing the reads.\n\n\n\n\nVelvet breaks up each read into k-mers of length k.\n\n\nA k-mer is a k length subsequence of the read.\n\n\nA 36 base pair long read would have 6 different 31-mers.\n\n\nThe k-mers and their reverse complements are added to a hash table to categorize them.\n\n\nEach k-mer is stored once but the number of times it appears is also recorded.\n\n\nThis step is performed by \u201cvelveth\u201d - one of the programs in the Velvet suite.\n\n\n\n\nStep 2: Constructing the de Bruijn graph.\n\n\n\n\nVelvet adds the k-mers one-by-one to the graph.\n\n\nAdjacent k-mers overlap by k-1 nucleotides.\n\n\nA k-mer which has no k-1 overlaps with any k-mer already on the graph starts a new node.\n\n\nEach node stores the average number of times its k-mers appear in the hash table.\n\n\nFigure 3 shows a section of a de Bruijn graph constructed by Velvet for k=5.\n\n\nDifferent sequences can be read off the graph by following a different path through it. (Figure 3)\n\n\n\n\nFigure 3: Section of a simple de Bruijn graph of reads with k-mer size 5. Coloured sequences are constructed by following the appropriately coloured line through the graph.\n \n(Base figure Zerbino et al 2008.)\n\n\n\n\nStep 3: Simplification of the graph.\n\n\n\n\nChain merging: When there are two connected nodes in the graph without a divergence, merge the two nodes.\n\n\nTip clipping: Tips are short (typically) chains of nodes that are disconnected on one end. They will be clipped if their length is \n 2 x k or their average k-mer depth is much less than the continuing path.\n\n\nBubble removal: Bubbles are redundant paths that start and end at the same nodes (Figure 4.) They are created by sequencing errors, biological variants or slightly varying repeat sequences.\n\n\nVelvet compares the paths using dynamic programming.\n\n\nIf they are highly similar, the paths are merged.\n\n\nError removal: Erroneous connections are removed by using a \u201ccoverage cutoff\u201d. Genuine short nodes which cannot be simplified should have a high coverage. An attempt is made to resolve repeats using the \u201cexpected coverage\u201d of the graph nodes.\n\n\nPaired end read information: Velvet uses algorithms called \u201cPebble\u201d and \u201cRock Band\u201d (Zerbino et al 2009) to order the nodes with respect to one another in order to scaffold them into longer contigs.\n\n\n\n\nFigure 4: Representation of \u201cbubbles\u201d in a Velvet de Bruijn graph.\n  \n(Base figure Zerbino et al 2008.)\n\n\n\n\nStep 4: Read off the contigs.\n\n\n\n\nFollow the chains of nodes through the graph and \u201cread off\u201d the bases to create the contigs.\n\n\nWhere there is an ambiguous divergence/convergence, stop the current contig and start a new one.\n\n\n\n\nK-mer size and coverage cutoff values\n\n\nThe size of the k-mers that construct the graph is very important and has a large effect on the outcome of the assembly. Generally, small k-mers create a graph with increased connectivity, more ambiguity (more divergences) and less clear \u201cpaths\u201d through the graph. Large k-mers produce graphs with less connectivity but higher specificity. The paths through the graph are clearer but they are less connected and prone to breaking down.\n\n\nThe coverage cutoff c used during the error correction step of Velvet also has a significant effect on the output of the assembly process. If c is too low, the assembly will contain nodes of the graph that are the product of sequencing errors and misconnections. If c is too high, it can create mis-assemblies in the contigs and destroys lots of useful data.\n\n\nEach dataset has its own optimum values for the k-mer size and the coverage cutoff used in the error removal step. Choosing them appropriately is one of the challenges faced by new users of the Velvet software.\n\n\nVelvet Optimiser\n\n\nThe Velvet Optimiser chooses the optimal values for k and c automatically by performing many runs of Velvet (partially in parallel) and interrogating the subsequent assemblies.  It uses different optimisation functions for k and c and these can be user controlled.\n\n\nIt requires the user to input a range of k values to search (to cut down on running time).\n\n\nReferences\n\n\nhttp://en.wikipedia.org/wiki/Sequence_assembly\n\n\nZerbino DR, Birney E, Velvet: algorithms for de novo short read assembly using de Bruijn graphs, Genome Research, 2008, 18:821-829\n\n\nZerbino DR, McEwen GK, Margulies EH, Birney E, Pebble and rock band: heuristic resolution of repeats and scaffolding in the velvet short-read de novo assembler. PLoS One. 2009; 4(12):e8407.\n\n\nGladman SL, Seemann T, Velvet Optimiser, http://www.vicbioinformatics.com/software.shtml 2009.", 
            "title": "Galaxy-Velvet"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#galaxy-velvet", 
            "text": "Modified from LSCC tutorial by  Simon Gladman  - VLSCI", 
            "title": "Galaxy - Velvet"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#tutorial-overview", 
            "text": "In this tutorial we cover the concepts of Microbial de novo assembly using a very small synthetic dataset from a well studied organism.", 
            "title": "Tutorial Overview"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#background", 
            "text": "Where is the data in this tutorial from?  The data for this tutorial is from a whole genome sequencing experiment of a multi-drug resistant strain of the bacterium  Staphylococcus aureus . The DNA was sequenced using an Illumina GAII sequencing machine. The data we are going to use consists of about 4 million x 75 base-pair, paired end reads (two FASTQ read files, one for each end of a DNA fragment.) The data was downloaded from the  NCBI Short Read Archive (SRA)  (http://www.ncbi.nlm.nih.gov/sra/). The specific sample is a public dataset published in April 2012 with SRA accession number ERR048396.  We will also use a FASTA file containing the sequences of the Illumina adapters used in the sequencing process. It is desirable to remove these as they are artificial sequences and not part of the bacterium that was sequenced.  We will use software called  Velvet  (Zerbino et al 2008) for the main de novo assembly, as well as some other peripheral software for pre- and post-processing of the data. Details of these can be found in the background document linked above.  The protocol:  We are performing a de novo assembly of the read data into contigs and then into scaffolds (appropriately positioned contigs loosely linked together). We firstly need to check the quality of the input data as this will help us choose the most appropriate range of input parameters for the assembly and will guide us on an appropriate quality trimming/cleanup strategy. We will then use an iterative method to assemble the reads using the  Velvet Optimiser  (a program that performs lots of Velvet assemblies searching for an optimum outcome.) Once this is complete we will obtain summary statistics on the final results (contigs) of the assembly.  More information about this protocol at the end of this tutorial.  The protocol in a nutshell:  Input:  Raw reads from sequencer run on microbial DNA sample.  Output:  File of assembled scaffolds/contigs and associated information.", 
            "title": "Background"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#input-data", 
            "text": "On the Galaxy tools panel, click on  Get data -  Upload File .  Click on the  Paste/Fetch Data  button.  Paste the URL:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/ERR048396_1.fastq.gz  into the text box. Change the type to  fastqsanger  (Not  fastqcsanger ).  Click on the  Paste/Fetch Data  button again.  Paste the URL:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/ERR048396_2.fastq.gz  into the text box and change it s type to  fastqsanger  as well.  Repeat the process for the last URL:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Assembly/illumina_adapters.fna  , but make it s type  fasta  Click on the  Start  button. Once all of the uploads are at 100%, click on the  Close  button.  When the files have finished uploading, rename them to \u2018ERR048396_1.fastq\u2019, \u2018ERR048396_2.fastq\u2019 and \u2018illumina_adapters.fna\u2019 respectively by clicking on the   icon to the top right of the file name in the right hand Galaxy panel (the history panel)   You should now have the following files in your Galaxy history:   ERR048396_1.fastq  - forward reads in fastq format  ERR048396_2.fastq  - reverse reads in fastq format  illumina_adapters.fa  - Illumina adapter sequences in fasta format   Click on the   icon to the top right of each fastq file to view the first part of the file", 
            "title": "Input data"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#section-1-quality-control", 
            "text": "The basic process here is to collect statistics about the quality of the reads in the sample FASTQ readsets. We will then evaluate their quality and choose an appropriate regime for quality filtering using Trimmomatic (a FASTQ read quality trimmer.)", 
            "title": "Section 1: Quality control"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#run-fastqc-on-both-input-read-files", 
            "text": "From the tools menu in the left hand panel of Galaxy, select  NGS QC and manipulation   FastQC: Comprehensive QC  (down the bottom of this category) and run with these parameters:  FASTQ reads :  ERR048396_1.fastq  Use default for other fields    Click  Execute  Now repeat the above process on the second read file:  ERR048396_2.fastq   It is important to do both read files as the quality can be very different between them.", 
            "title": "Run FastQC on both input read files"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-1-screenshot-of-fastqc-interface-in-galaxy", 
            "text": "", 
            "title": "Figure 1: Screenshot of FastQC interface in Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#examine-the-fastqc-output", 
            "text": "You should have two output objects from the first step:   FastQC_ERR048396_1.fastqc.html  FastQC_ERR048396_2.fastqc.html   These are a html outputs which show the results of all of the tests FastQC performed on the read files.   Click on the   icon of each of these objects in turn to see the FastQC output.   The main parts of the output to evaluate are:   Basic statistics. This section tells us that the ASCII quality encoding format used was Sanger/Illumina 1.9 and the reads are length 75 and the percent GC content of the entire file is 35%.  Per base sequence quality. In the plot you should see that most of the early bases are up around the  32  mark and then increase to 38-40, which is very high quality; The spread of quality values for the last few bases increases and some of the outliers have quality scores of less than 30. This is a very good quality dataset. 20 is often used as a cutoff for reliable quality.", 
            "title": "Examine the FastQC output"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-2-screenshot-of-fastqc-output-in-galaxy", 
            "text": "", 
            "title": "Figure 2: Screenshot of FastQC output in Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#quality-trim-the-reads-using-trimmomatic", 
            "text": "From the tools menu in the left hand panel of Galaxy, select  NGS QC and manipulation   Trimmomatic  and run with these parameters (only the non-default selections are listed here):   Input FASTQ file (R1/first of pair) :  ERR048396_1.fastq  Input FASTQ file (R2/second of pair) :  ERR048396_2.fastq  Perform initial ILLUMINACLIP step? :  Yes  Adapter sequences to use :  TruSeq3 (additional seqs) (paired end, for MiSeq and HiSeq)  How accurate   read alignment :  40  How accurate   against a read :  15  We will use the default settings for the SLIDING_WINDOW operation but we need to add a few more Trimmomatic operations.  Click  Insert Trimmomatic Operation  Add  Cut bases   (LEADING)  Minimum quality required to keep a base :  15    Repeat the  Insert Trimmomatic Operation  for:  Trim trailing bases, minimum quality:  15  Minimum length read:  35       Click  Execute", 
            "title": "Quality trim the reads using Trimmomatic."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-3-screenshot-of-trimmomatic-inputs-in-galaxy", 
            "text": "", 
            "title": "Figure 3: Screenshot of Trimmomatic inputs in Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#examine-the-trimmomatic-output-fastq-files", 
            "text": "You should have 4 new objects in your history from the output of Trimmomatic:   Trimmomatic on data 2 and data 1 (R1 Paired)  Trimmomatic on data 2 and data 1 (R1 Unpaired)  Trimmomatic on data 2 and data 1 (R2 Paired)  Trimmomatic on data 2 and data 1 (R2 Unpaired)   Click on the   on one of the objects to look at its contents. You\u2019ll notice that not all of the reads are the same length now, as they have had the illumina adapters cut out of them and they\u2019ve been quality trimmed.", 
            "title": "Examine the Trimmomatic output FastQ files."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#section-2-assemble-reads-into-contigs-with-velvet-and-the-velvet-optimiser", 
            "text": "The aim here is to assemble the trimmed reads into contigs/scaffolds using Velvet and the Velvet Optimiser.  We will use a single tool, Velvet Optimiser, which takes the trimmed reads from Trimmomatic and performs numerous Velvet assemblies to find the best one. We need to add the reads in two separate libraries. One for the still paired reads and the other for the singleton reads orphaned from their pairs by the trimming process.  Click here for a more detailed explanation of Velvet assemblies and the Velvet Optimiser", 
            "title": "Section 2: Assemble reads into contigs with Velvet and the Velvet Optimiser"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#de-novo-assembly-of-the-reads-into-contigs", 
            "text": "From the tools menu in the left hand panel of Galaxy, select  NGS: Assembly -  Velvet Optimiser  and run with these parameters (only the non-default selections are listed here):  Start k-mer value :  55  End k-mer value :  69  In the input files section:  Select first set of reads :  Trimmomatic on data 2 and data 1 (R1 paired)  Select second set of reads :  Trimmomatic on data 2 and data 1 (R2 paired)    Click the  Insert Input Files  button and add the following:  Single or paired end reads :  Single  Select the reads :  Trimmomatic on data 2 and data 1 (R1 unpaired)    Repeat the above process to add the other unpaired read set  Trimmomatic on data 2 and data 1 (R2 unpaired)  as well.    Click  Execute .", 
            "title": "De novo assembly of the reads into contigs"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-4-screenshot-of-velvet-optimiser-inputs-in-galaxy", 
            "text": "", 
            "title": "Figure 4: Screenshot of Velvet Optimiser inputs in Galaxy"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#examine-assembly-output", 
            "text": "Once step 1 is complete, you should now have 2 new objects in your history:   VelvetOptimiser on data 9, data 7, and others: Contigs    VelvetOptimiser on data 9, data 7, and others: Contig Stats  Click on the   icon of the various objects.    Contigs: You\u2019ll see the first MB of the file. Note that the contigs are named NODE_XX_length_XXXX_cov_XXX.XXX. This information tells you how long (in k-mer length) each contig is and what it\u2019s average k-mer coverage is. (See detailed explanation of Velvet and Velvet Optimiser for explanation of k-mer coverage and k-mer length.)    Contig stats: This shows a table of the contigs and their k-mer coverages and which read library contributed to the coverage. It is interesting to note that some of them have much higher coverage than the average. These are most likely to be repeated contigs. (Things like ribosomal RNA and IS elements.)", 
            "title": "Examine assembly output"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-5-screenshot-of-assembled-contigs-a-and-contig-stats-b", 
            "text": "", 
            "title": "Figure 5: Screenshot of assembled contigs (a) and contig stats (b)"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#a", 
            "text": "", 
            "title": "a"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#b", 
            "text": "", 
            "title": "b"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#calculate-some-statistics-on-the-assembled-contigs", 
            "text": "From the tools menu in the left hand panel of Galaxy, select  FASTA Manipulation -  Fasta Statistics  and run with these parameters:  Fasta or multifasta file :  Velvet Optimiser   Contigs    Click  Execute  Examine the Fasta Stats output   You should now have one more object in your history:  Fasta Statistics on data 10: Fasta summary stats  Click on the   icon next to this object and have a look at the output. You\u2019ll see a statistical summary of the contigs including various length stats, the % GC content, the n50 as well as the number of contigs and the number of N bases contained in them.", 
            "title": "Calculate some statistics on the assembled contigs"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#section-3-extension", 
            "text": "Examine the contig coverage depth and blast a high coverage contig against a protein database.", 
            "title": "Section 3: Extension."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#examine-the-contig-coverage-depth", 
            "text": "Look at the Contig Stats data (Velvet Optimiser vlsci on data 8, data 9, and data 7: Contig stats) by clicking on the   icon. Note that column 2 contig length (lgth), shows a number of very short contigs (some are length 1).   We can easily filter out these short contigs from this information list by using the  Filter and Sort -  Filter tool.  Set the following:  Filter :  Velvet Optimiser on data 8, data 7 and others: Contig stats  With the following condition :  c2   100    Click  Execute   The new data object in the history is called:  Filter on data 11 .  Click on its   icon to view it. Look through the list taking note of the coverages. Note that the average of the coverages (column 6) seems to be somewhere between 16 and 32.  There are a lot of contigs with coverage 16. We could say that these contigs only appear once in the genome of the bacteria. Therefore, contigs with double this coverage would appear twice. Note that some of the coverages are  400! These contigs will appear in the genome more than 20 times!  Lets have a look at one of these contigs and see if we can find out what it is.", 
            "title": "Examine the contig coverage depth."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#extract-a-single-sequence-from-the-contigs-file", 
            "text": "Note the contig number (column 1 in the Contig stats file) of a contig with a coverage of over 300. There should be a few of them. We need to extract the fasta sequence of this contig from the contigs multifasta so we can see it more easily.  To do this we will use the tool:   Fasta manipulation -  Fasta Extract Sequence  Set the following:  Fasta or multifasta file :  Velvet Optimiser   : Contigs  Sequence ID (or partial):  NODE_1_  (for example)    Click  Execute   The new data object in the history is called:  Fasta Extract Sequence on data 10: Fasta .  Click on its   icon to view it. It is a single sequence in fasta format.", 
            "title": "Extract a single sequence from the contigs file."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#blast-sequence-to-determine-what-it-contains", 
            "text": "We want to find out what this contig is or what kind of coding sequence (if any) it contains. So we will blast the sequence using the NCBI blast website. (External to Galaxy). To do this:   Bring up the sequence of the contig into the main window of the browser by clicking on the   icon if it isn\u2019t already.  Select the entire sequence by clicking and dragging with the mouse or by pressing ctrl-a in the browser.  Copy the selected sequence to the clipboard.  Open a new tab of your browser and point it to: http://blast.ncbi.nlm.nih.gov/Blast.cgi  Under the BASIC BLAST section, click \u201cblastx\u201d.  Paste the sequence into the large text box labelled: Enter Accession number(s), gi(s) or FASTA sequence(s).  Change the Genetic code to: Bacteria and Archaea (11)  Click the button labelled: BLAST   After a while the website will present a report of the blast run. Note that the sequence we blasted (if you chose NODE_1) is identical to part of a transposase gene (IS256) from a similar Staphylococcus aureus bacteria. These transposases occur frequently as repeats in bacterial genomes and so we shouldn\u2019t be surprised at its very high coverage.", 
            "title": "Blast sequence to determine what it contains."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#figure-6-screenshot-of-the-output-from-the-ncbi-blast-website", 
            "text": "", 
            "title": "Figure 6: Screenshot of the output from the NCBI Blast website"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#de-novo-assembly-with-velvet-and-the-velvet-optimiser", 
            "text": "", 
            "title": "De novo assembly with Velvet and the Velvet Optimiser."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#velvet", 
            "text": "Velvet is software to perform dna assembly from short reads by manipulating de Bruijn graphs. It is capable of forming long contigs (n50 of in excess of 150kb) from paired end short reads. It has several input parameters for controlling the structure of the de Bruijn graph and these must be set optimally to get the best assembly possible. Velvet can read Fasta, FastQ, sam or bam files. However, it ignores any quality scores and simply relies on sequencing depth to resolve errors. The Velvet Optimiser software performs many Velvet assemblies with various parameter sets and searches for the optimal assembly automatically.", 
            "title": "Velvet"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#de-bruijn-graphs", 
            "text": "A de Bruijn graph is a directed graph which represents overlaps between sequences of symbols. The size of the sequence contained in the nodes of the graph is called the word-length or k-mer size. In Figure 2, the word length is 3. The two symbols are 1 and 0. Each node in the graph has the last two symbols of the previous node and 1 new symbol. Sequences of symbols can be produced by traversing the graph and adding the \u201cnew\u201d symbol to the growing sequence.  Figure 2: A de Bruijn graph of word length 3 for the symbols 1 and 0.   From: https://cameroncounts.wordpress.com/2015/02/28/1247/  Velvet constructs a de Bruijn graph of the reads. It has 4 symbols (A, C, G and T - N\u2019s are converted to A\u2019s) The word length (or k-mer size) is one of Velvet\u2019s prime parameters.  Velvet is not the only assembly software that works in this manner. Euler, Edena and SOAP de novo are examples of others.", 
            "title": "de Bruijn graphs"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#the-velvet-algorithm", 
            "text": "", 
            "title": "The Velvet algorithm"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#step-1-hashing-the-reads", 
            "text": "Velvet breaks up each read into k-mers of length k.  A k-mer is a k length subsequence of the read.  A 36 base pair long read would have 6 different 31-mers.  The k-mers and their reverse complements are added to a hash table to categorize them.  Each k-mer is stored once but the number of times it appears is also recorded.  This step is performed by \u201cvelveth\u201d - one of the programs in the Velvet suite.", 
            "title": "Step 1: Hashing the reads."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#step-2-constructing-the-de-bruijn-graph", 
            "text": "Velvet adds the k-mers one-by-one to the graph.  Adjacent k-mers overlap by k-1 nucleotides.  A k-mer which has no k-1 overlaps with any k-mer already on the graph starts a new node.  Each node stores the average number of times its k-mers appear in the hash table.  Figure 3 shows a section of a de Bruijn graph constructed by Velvet for k=5.  Different sequences can be read off the graph by following a different path through it. (Figure 3)   Figure 3: Section of a simple de Bruijn graph of reads with k-mer size 5. Coloured sequences are constructed by following the appropriately coloured line through the graph.   (Base figure Zerbino et al 2008.)", 
            "title": "Step 2: Constructing the de Bruijn graph."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#step-3-simplification-of-the-graph", 
            "text": "Chain merging: When there are two connected nodes in the graph without a divergence, merge the two nodes.  Tip clipping: Tips are short (typically) chains of nodes that are disconnected on one end. They will be clipped if their length is   2 x k or their average k-mer depth is much less than the continuing path.  Bubble removal: Bubbles are redundant paths that start and end at the same nodes (Figure 4.) They are created by sequencing errors, biological variants or slightly varying repeat sequences.  Velvet compares the paths using dynamic programming.  If they are highly similar, the paths are merged.  Error removal: Erroneous connections are removed by using a \u201ccoverage cutoff\u201d. Genuine short nodes which cannot be simplified should have a high coverage. An attempt is made to resolve repeats using the \u201cexpected coverage\u201d of the graph nodes.  Paired end read information: Velvet uses algorithms called \u201cPebble\u201d and \u201cRock Band\u201d (Zerbino et al 2009) to order the nodes with respect to one another in order to scaffold them into longer contigs.   Figure 4: Representation of \u201cbubbles\u201d in a Velvet de Bruijn graph.    (Base figure Zerbino et al 2008.)", 
            "title": "Step 3: Simplification of the graph."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#step-4-read-off-the-contigs", 
            "text": "Follow the chains of nodes through the graph and \u201cread off\u201d the bases to create the contigs.  Where there is an ambiguous divergence/convergence, stop the current contig and start a new one.", 
            "title": "Step 4: Read off the contigs."
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#k-mer-size-and-coverage-cutoff-values", 
            "text": "The size of the k-mers that construct the graph is very important and has a large effect on the outcome of the assembly. Generally, small k-mers create a graph with increased connectivity, more ambiguity (more divergences) and less clear \u201cpaths\u201d through the graph. Large k-mers produce graphs with less connectivity but higher specificity. The paths through the graph are clearer but they are less connected and prone to breaking down.  The coverage cutoff c used during the error correction step of Velvet also has a significant effect on the output of the assembly process. If c is too low, the assembly will contain nodes of the graph that are the product of sequencing errors and misconnections. If c is too high, it can create mis-assemblies in the contigs and destroys lots of useful data.  Each dataset has its own optimum values for the k-mer size and the coverage cutoff used in the error removal step. Choosing them appropriately is one of the challenges faced by new users of the Velvet software.", 
            "title": "K-mer size and coverage cutoff values"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#velvet-optimiser", 
            "text": "The Velvet Optimiser chooses the optimal values for k and c automatically by performing many runs of Velvet (partially in parallel) and interrogating the subsequent assemblies.  It uses different optimisation functions for k and c and these can be user controlled.  It requires the user to input a range of k values to search (to cut down on running time).", 
            "title": "Velvet Optimiser"
        }, 
        {
            "location": "/dna/denovo/galaxy-velvet/galaxy-velvet/#references", 
            "text": "http://en.wikipedia.org/wiki/Sequence_assembly  Zerbino DR, Birney E, Velvet: algorithms for de novo short read assembly using de Bruijn graphs, Genome Research, 2008, 18:821-829  Zerbino DR, McEwen GK, Margulies EH, Birney E, Pebble and rock band: heuristic resolution of repeats and scaffolding in the velvet short-read de novo assembler. PLoS One. 2009; 4(12):e8407.  Gladman SL, Seemann T, Velvet Optimiser, http://www.vicbioinformatics.com/software.shtml 2009.", 
            "title": "References"
        }, 
        {
            "location": "/dna/anno/prokka/", 
            "text": "Prokka on Galaxy\n\n\nBackground\n\n\nGenome annotation involves finding and describing particular features, such as genes, tRNAs and rRNAs. This tutorial will demonstrate how to annotate an assembled bacterial genome using the tool Prokka. Link to \nProkka on github\n; link to \nProkka citation\n.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to :\n\n\n\n\ninput files into Prokka\n\n\nchange settings\n\n\nrun Prokka, and\n\n\nexamine the output: annotated genome.\n\n\n\n\nPre-requisites\n\n\n\n\na mGVL and galaxy instance\n\n\n\n\nStart\n\n\n\n\nopen your galaxy instance in your mGVL\n\n\n\n\nInput data\n\n\n\n\nassembled contigs, e.g. \nSPAdes_contigs.fasta\n\n\n\n\nHow it works\n\n\n\n\n\n\nProkka compares the input contigs with various databases to identify coding sequences, rRNA genes, tRNA genes, non-coding RNA, and signal leader peptides.\n\n\n\n\n\n\nThese databases are maintained by different organisations, and include information about known genomic features and their locations. Prokka includes a local copy.\n\n\n\n\n\n\nRun Prokka\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n  \n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nFIXME: actually we want to have a different locus tag for each sample for later use in Roary. Is there some problem here with the length of the locus tag that can be used?\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nYes\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nGenus Name\n: \nStaphylococcus\n  \n\n\nSpecies Name\n: \naureus\n  \n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\nClick \nExecute\n. This may take x minutes.\n\n\n\n\n\n\n\n\nExamine the output\n\n\nOnce Prokka has finished, examine each of its output files.\n\n\n\n\n\n\nThe gff and gbk files contains all of the information about all of the features annotated (in different formats.)\n\n\n\n\n\n\nsummary.gff\n: a list of all the features found, listed in order of their location (starting at the start of contig number 1). Each row is a genomic feature and its location. Column 2 is the source - the database used to find the feature. Column 3 is the feature - e.g. CDS, tRNA.\n\n\n\n\n\n\nsummary.gbk\n: the contigs listed in order. For each contig, the features are listed (e.g. CDS name and translation), followed by the sequence of the whole contig.\n\n\n\n\n\n\nThe txt file contains a summary of the number of features annotated.\n\n\n\n\nThe faa file contains the protein sequences of the genes annotated.\n\n\n\n\nThe ffn file contains the nucleotide sequences of the genes annotated.\n\n\n\n\n\n\nDownload the gff file to your local computer: click on the file name with the .gff extension, and then click on the disk icon \n.\n\n\n\n\n\n\n\n\nAnnotated features\n\n\nNow that we have annotated the draft genome sequence, we would like to view the sequence in the Artemis genome viewer.\n\n\n\n\nOpen Artemis and load the downloaded .gff file.\n\n\nThe top panel shows an overview - here we can see annotated genes and other features.\n\n\nThe middle panel shows the DNA sequence and amino acid translations in 6 frames.\n\n\nThe bottom panel shows a text summary of the features.\n\n\nScroll left and right with the horizontal bars under each panel.\n\n\nZoom with the vertical bars to the right.\n\n\n\n\n\n\nWhat Next?\n\n\n\n\nDetermine core and pan genomes using \nRoary\n.", 
            "title": "Prokka in Galaxy"
        }, 
        {
            "location": "/dna/anno/prokka/#prokka-on-galaxy", 
            "text": "", 
            "title": "Prokka on Galaxy"
        }, 
        {
            "location": "/dna/anno/prokka/#background", 
            "text": "Genome annotation involves finding and describing particular features, such as genes, tRNAs and rRNAs. This tutorial will demonstrate how to annotate an assembled bacterial genome using the tool Prokka. Link to  Prokka on github ; link to  Prokka citation .", 
            "title": "Background"
        }, 
        {
            "location": "/dna/anno/prokka/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to :   input files into Prokka  change settings  run Prokka, and  examine the output: annotated genome.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/dna/anno/prokka/#pre-requisites", 
            "text": "a mGVL and galaxy instance", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dna/anno/prokka/#start", 
            "text": "open your galaxy instance in your mGVL", 
            "title": "Start"
        }, 
        {
            "location": "/dna/anno/prokka/#input-data", 
            "text": "assembled contigs, e.g.  SPAdes_contigs.fasta", 
            "title": "Input data"
        }, 
        {
            "location": "/dna/anno/prokka/#how-it-works", 
            "text": "Prokka compares the input contigs with various databases to identify coding sequences, rRNA genes, tRNA genes, non-coding RNA, and signal leader peptides.    These databases are maintained by different organisations, and include information about known genomic features and their locations. Prokka includes a local copy.", 
            "title": "How it works"
        }, 
        {
            "location": "/dna/anno/prokka/#run-prokka", 
            "text": "In Galaxy, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):  Contigs to annotate :  SPAdes contigs (fasta)     Locus tag prefix ( locustag) : P  FIXME: actually we want to have a different locus tag for each sample for later use in Roary. Is there some problem here with the length of the locus tag that can be used?  Force GenBank/ENA/DDJB compliance ( compliant) :  Yes  Sequencing Centre ID ( centre) : V  Genus Name :  Staphylococcus     Species Name :  aureus     Use genus-specific BLAST database   No     Click  Execute . This may take x minutes.", 
            "title": "Run Prokka"
        }, 
        {
            "location": "/dna/anno/prokka/#examine-the-output", 
            "text": "Once Prokka has finished, examine each of its output files.    The gff and gbk files contains all of the information about all of the features annotated (in different formats.)    summary.gff : a list of all the features found, listed in order of their location (starting at the start of contig number 1). Each row is a genomic feature and its location. Column 2 is the source - the database used to find the feature. Column 3 is the feature - e.g. CDS, tRNA.    summary.gbk : the contigs listed in order. For each contig, the features are listed (e.g. CDS name and translation), followed by the sequence of the whole contig.    The txt file contains a summary of the number of features annotated.   The faa file contains the protein sequences of the genes annotated.   The ffn file contains the nucleotide sequences of the genes annotated.    Download the gff file to your local computer: click on the file name with the .gff extension, and then click on the disk icon  .", 
            "title": "Examine the output"
        }, 
        {
            "location": "/dna/anno/prokka/#annotated-features", 
            "text": "Now that we have annotated the draft genome sequence, we would like to view the sequence in the Artemis genome viewer.   Open Artemis and load the downloaded .gff file.  The top panel shows an overview - here we can see annotated genes and other features.  The middle panel shows the DNA sequence and amino acid translations in 6 frames.  The bottom panel shows a text summary of the features.  Scroll left and right with the horizontal bars under each panel.  Zoom with the vertical bars to the right.", 
            "title": "Annotated features"
        }, 
        {
            "location": "/dna/anno/prokka/#what-next", 
            "text": "Determine core and pan genomes using  Roary .", 
            "title": "What Next?"
        }, 
        {
            "location": "/dna/anno/prokka_cmdline/", 
            "text": "Prokka on commandline\n\n\n\n\nssh to your mGVL\n\n\nwget data - scaffolds of .fna for several species\n\n\n(alternatively - have already put data on your mGVL)\n\n\ntype in:\n\n\n\n\nprokka --outdir [name of output folder for 1 sample] --locustag [tag eg sample number] [fna filename]\n\n\n\n\n\n\nmake a new directory for the gff files e.g. \ngff_files\n\n\n\n\nmv -v \n/\n.gff gff_files/  (means move any .gff files into that folder)\n\n\n\n\n\n\nFIXME: prokka options see manual", 
            "title": "Prokka on commandline"
        }, 
        {
            "location": "/dna/anno/prokka_cmdline/#prokka-on-commandline", 
            "text": "ssh to your mGVL  wget data - scaffolds of .fna for several species  (alternatively - have already put data on your mGVL)  type in:   prokka --outdir [name of output folder for 1 sample] --locustag [tag eg sample number] [fna filename]   make a new directory for the gff files e.g.  gff_files   mv -v  / .gff gff_files/  (means move any .gff files into that folder)    FIXME: prokka options see manual", 
            "title": "Prokka on commandline"
        }, 
        {
            "location": "/dna/snps/snippy/", 
            "text": "Snippy\n\n\ncmdline\n\n\nThis tutorial will demonstrate how to find variants in a bacterial genome using Snippy. Variants are found by comparing to a reference genome of the same species.\n\n\nGithub link to Snippy\n\n\nPre-requisites\n\n\n\n\nconnect to your GVL - cmdline\n\n\nbackground knowledge: variant calling\n\n\n\n\nStart\n\n\n\n\nlog in to your virtual machine via terminal\n\n\nnavigate to the place where you want Snippy to run.\n\n\nmake a folder called snippy - \nmkdir snippy\n\n\nmove into that folder - \ncd snippy\n\n\n\n\nInput\n\n\nRaw sequence reads\n\n\n\n\nIllumina paired-end reads from a bacteria in FASTQ format.\n\n\nThese reads are from \nPasteurella multocida\n, from EMBL-EBI ENA. We will use \nwget\n to download them via FTP.\n\n\nin the snippy folder,\n\n\n\n\nwget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR125/003/SRR1257473/SRR1257473_1.fastq.gz\n\n\n\n\nwget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR125/003/SRR1257473/SRR1257473_2.fastq.gz\n\n\n\n\n\n\nThese files are compressed and so end in .gz. Snippy can use these .gz read files directly without unzipping.\n\n\n\n\nReference genome\n\n\n\n\nReference genome from the same species, \nPasteurella multocida\n, from EMBL-EBI Ensembl genomes, in FASTA format.\n\n\nin the snippy folder,\n\n\n\n\nwget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-31/fasta/bacteria_104_collection/pasteurella_multocida_subsp_multocida_gca_001027695/dna/Pasteurella_multocida_subsp_multocida_gca_001027695.ASM102769v1.31.dna.genome.fa.gz\n\n\n\n\n\n\nThis file is also compressed into .gz format. This needs to be unzipped:\n\n\n\n\ngunzip ftp://ftp.ensemblgenomes.org/pub/bacteria/release-31/fasta/bacteria_104_collection/pasteurella_multocida_subsp_multocida_gca_001027695/dna/Pasteurella_multocida_subsp_multocida_gca_001027695.ASM102769v1.31.dna.genome.fa.gz\n\n\n\n\n\n\nThe file will now end in .fa (which is fasta format, and Snippy can use).\n\n\n\n\nHow it works\n\n\n\n\nReads are mapped to the reference genome using BWA: this makes a BAM file\n\n\nBAM file and the ref genome sequence sent to Freebayes\n\n\nFreebayes finds differences between the reads and the reference, and calls the variants.\n\n\n\n\nRun Snippy\n\n\n\n\ncpus: choose number of cpus to use [or it uses a default] - here we will use 16\n\n\noutdir: choose a name for the output directory, where results will go - here we will use \nmysnps\n\n\nref: the input reference genome filename\n\n\nR1: the input R1 reads filename\n\n\nR2: the input R2 reads filename\n\n\nto run snippy:\n\n\n\n\nsnippy --cpus 16 --outdir mysnps --ref [filename.fa] --R1 [R1.fastq.gz] --R2 [R2.fastq.gz]\n\n\n\n\nOutput\n\n\n\n\n17 output files\n\n\nlist all the output files (that were put into the \nmysnps\n folder):\n\n\n\n\nls mysnps\n\n\n\n\n\n\nlook at the first 10 lines of the snps.tab file\n\n\n\n\nhead -10 mysnps/snps.tab\n\n\n\n\n\n\nlook at these columns: chromosome (CHROM), genomic position (POS), variant type (TYPE), nucleotide state in the ref (REF), nucleotide state in the input sample (ALT), and the frequency counts of REF and ALT (EVIDENCE).\n\n\nFIXME: screenshot with arrows\n\n\nFIXME: filter for quality?\n\n\nFIXME: load reference and the tabular vcf file into JBrowse/Artemis/IGV to view the genome and the snps.\n\n\nFIXME: is there anything we are looking for in particular? e.g. number of variants, existing known variants, variants in particular genes, AMR variants?\n\n\n\n\nNext", 
            "title": "Snippy on commandline"
        }, 
        {
            "location": "/dna/snps/snippy/#snippy", 
            "text": "cmdline  This tutorial will demonstrate how to find variants in a bacterial genome using Snippy. Variants are found by comparing to a reference genome of the same species.  Github link to Snippy", 
            "title": "Snippy"
        }, 
        {
            "location": "/dna/snps/snippy/#pre-requisites", 
            "text": "connect to your GVL - cmdline  background knowledge: variant calling", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dna/snps/snippy/#start", 
            "text": "log in to your virtual machine via terminal  navigate to the place where you want Snippy to run.  make a folder called snippy -  mkdir snippy  move into that folder -  cd snippy", 
            "title": "Start"
        }, 
        {
            "location": "/dna/snps/snippy/#input", 
            "text": "", 
            "title": "Input"
        }, 
        {
            "location": "/dna/snps/snippy/#raw-sequence-reads", 
            "text": "Illumina paired-end reads from a bacteria in FASTQ format.  These reads are from  Pasteurella multocida , from EMBL-EBI ENA. We will use  wget  to download them via FTP.  in the snippy folder,   wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR125/003/SRR1257473/SRR1257473_1.fastq.gz  wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR125/003/SRR1257473/SRR1257473_2.fastq.gz   These files are compressed and so end in .gz. Snippy can use these .gz read files directly without unzipping.", 
            "title": "Raw sequence reads"
        }, 
        {
            "location": "/dna/snps/snippy/#reference-genome", 
            "text": "Reference genome from the same species,  Pasteurella multocida , from EMBL-EBI Ensembl genomes, in FASTA format.  in the snippy folder,   wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-31/fasta/bacteria_104_collection/pasteurella_multocida_subsp_multocida_gca_001027695/dna/Pasteurella_multocida_subsp_multocida_gca_001027695.ASM102769v1.31.dna.genome.fa.gz   This file is also compressed into .gz format. This needs to be unzipped:   gunzip ftp://ftp.ensemblgenomes.org/pub/bacteria/release-31/fasta/bacteria_104_collection/pasteurella_multocida_subsp_multocida_gca_001027695/dna/Pasteurella_multocida_subsp_multocida_gca_001027695.ASM102769v1.31.dna.genome.fa.gz   The file will now end in .fa (which is fasta format, and Snippy can use).", 
            "title": "Reference genome"
        }, 
        {
            "location": "/dna/snps/snippy/#how-it-works", 
            "text": "Reads are mapped to the reference genome using BWA: this makes a BAM file  BAM file and the ref genome sequence sent to Freebayes  Freebayes finds differences between the reads and the reference, and calls the variants.", 
            "title": "How it works"
        }, 
        {
            "location": "/dna/snps/snippy/#run-snippy", 
            "text": "cpus: choose number of cpus to use [or it uses a default] - here we will use 16  outdir: choose a name for the output directory, where results will go - here we will use  mysnps  ref: the input reference genome filename  R1: the input R1 reads filename  R2: the input R2 reads filename  to run snippy:   snippy --cpus 16 --outdir mysnps --ref [filename.fa] --R1 [R1.fastq.gz] --R2 [R2.fastq.gz]", 
            "title": "Run Snippy"
        }, 
        {
            "location": "/dna/snps/snippy/#output", 
            "text": "17 output files  list all the output files (that were put into the  mysnps  folder):   ls mysnps   look at the first 10 lines of the snps.tab file   head -10 mysnps/snps.tab   look at these columns: chromosome (CHROM), genomic position (POS), variant type (TYPE), nucleotide state in the ref (REF), nucleotide state in the input sample (ALT), and the frequency counts of REF and ALT (EVIDENCE).  FIXME: screenshot with arrows  FIXME: filter for quality?  FIXME: load reference and the tabular vcf file into JBrowse/Artemis/IGV to view the genome and the snps.  FIXME: is there anything we are looking for in particular? e.g. number of variants, existing known variants, variants in particular genes, AMR variants?", 
            "title": "Output"
        }, 
        {
            "location": "/dna/snps/snippy/#next", 
            "text": "", 
            "title": "Next"
        }, 
        {
            "location": "/dna/pan/roary/", 
            "text": "Roary\n\n\ncmdline\n\n\nThis tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial species, using Roary.\n\n\nRoary code and manual on github\n\n\nRoary paper\n\n\nPre-requisites\n\n\n\n\nbackground: pan genomes\n\n\na mGVL instance\n\n\n\n\nStart\n\n\n\n\nvia local Terminal\n: in your terminal, ssh into your mGVL, but make sure you put in -X -Y after ssh so that xquartz can view files later. (FIXME: word better)\n\n\nor via virtual desktop\n: Go to your mGVL dashboard. Click on the link to the Lubuntu desktop. A virtual desktop will open in a new browser window. Enter username: ubunutu; and your GVL password. Click on terminal in the top left corner.\n\n\n\n\nInput data\n\n\n\n\nRoary takes .gff files produced by Prokka. A gff file has sequences and annotations.\n\n\nfile formats\n FIXME: link to proper page\n\n\nGet files into mGVL. (FIXME: explain how, wget etc or from GenomeSpace)\n\n\nput all gff files into a folder\n\n\nFIXME: choose a good sample set - ideally something that usefully shows how AMR genes can be present/absence in a group? for a draft can use the Listeria tutorial at https://github.com/microgenomics/tutorials/blob/master/pangenome.md\n\n\n\n\nRun\n\n\n\n\nnavigate into the place where the gff folder is.\n\n\n\n\nroary -f ./results ./gff_files/*.gff\n\n\n\n\n\n\n-f ./results\n puts the output into a directory called results\n\n\n\n\nHow it works\n\n\n\n\nBased on the input genomes, Roary works out which genes are shared between all (core) and which are not (accessory).\n\n\nIt uses the protein-coding genes from each of the input genomes.\n\n\nconverts to protein seqs\n\n\nsimilar protein seqs are clustered progressively.\n\n\neach sample: will be labelled with presence/absence of orthologous genes.\n\n\n\n\nOutput\n\n\nsummary statistics:\n\n\nmore summary_statistics.txt\n\n\n\n\n\n\nyou will see the number of core genes, shell genes, etc.\n\n\nq\n to exit viewing\n\n\n\n\ngene presence/absence graphically:\n\n\nroary2svg.pl gene_presence_absence.csv \n pan_genome.svg\n\n\n\n\n\n\n(if you have logged in with -X -Y)\n\n\n\n\nfirefox pan_genome.svg \n\n\n\n\n\n\n\nthen \nenter\n\n\nthe \n makes it run in the background\n\n\na firefox window should open with the svg image\n\n\n(later: close the firefox window to stop this job running in the background)\n\n\n\n\nlist of genes that are present/absent:\n\n\n\n\nview the gene_presence_absence.csv by (FIXME)\n\n\nlots of information about this file in the roary website (FIXME summarize?)\n\n\n\n\nquery the pan genome:\n\n\n\n\ncopy the input .gff files into the results folder (FIXME: do this earlier)\n\n\ncd into this folder\n\n\n\n\nquery_pan_genome -a intersection *.gff\n\n\n\n\n\n\nthis finds the core genes\n\n\n\n\nmore pan_genome_results\n\n\n\n\n\n\nshows the list of genes found in the core genome.\n\n\nq\n to exit viewing\n\n\n\n\nAdvanced options\n\n\nFIXME: update firefox on mGVL so can run phandango\n\n\nRun roary and create an alignment of core genes:\n\n\nroary -f ./results -e -n -p 8 ./gff_files/*.gff\n\n\n\n\n\n\n-f ./results\n puts the output into a directory called results\n\n\n-e -n\n creates an alignment of core genes using mafft\n\n\n-p 8\n gives 8 threads - optional, if you know how many you have\n\n\n\n\nGenerate a tree based on the presence/absence of core genes:\n\n\n\n\nnavigate into the results folder that you want to use.\n\n\n\n\nFastTree -nt -gtr core_gene_alignment.aln \n my_tree.newick\n\n\n\n\n\n\n(By default, roary will also have created a (very quick) tree from the accessory genes.)\n\n\nFastTree information and options\n.\n\n\n\n\nUse roary_plots.py to generate plots:\n\n\n\n\nnavigate into the results folder that you want to use.\n\n\n\n\npython roary_plots.py core_gene_alignment.nwk gene_presence_absence.csv\n\n\n\n\n\n\noutput: pangenome matrix, frequency plot, pie chart.\n\n\nview these by typing \nfirefox [filename]\n and a firefox window will open to show the image. You need to close the window before you open the next image.\n\n\n\n\nWhat next?\n\n\nView using Phandango; \ntutorial here.\n\n\nMore information\n\n\n\n\nanother Roary tutorial", 
            "title": "Roary"
        }, 
        {
            "location": "/dna/pan/roary/#roary", 
            "text": "cmdline  This tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial species, using Roary.  Roary code and manual on github  Roary paper", 
            "title": "Roary"
        }, 
        {
            "location": "/dna/pan/roary/#pre-requisites", 
            "text": "background: pan genomes  a mGVL instance", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dna/pan/roary/#start", 
            "text": "via local Terminal : in your terminal, ssh into your mGVL, but make sure you put in -X -Y after ssh so that xquartz can view files later. (FIXME: word better)  or via virtual desktop : Go to your mGVL dashboard. Click on the link to the Lubuntu desktop. A virtual desktop will open in a new browser window. Enter username: ubunutu; and your GVL password. Click on terminal in the top left corner.", 
            "title": "Start"
        }, 
        {
            "location": "/dna/pan/roary/#input-data", 
            "text": "Roary takes .gff files produced by Prokka. A gff file has sequences and annotations.  file formats  FIXME: link to proper page  Get files into mGVL. (FIXME: explain how, wget etc or from GenomeSpace)  put all gff files into a folder  FIXME: choose a good sample set - ideally something that usefully shows how AMR genes can be present/absence in a group? for a draft can use the Listeria tutorial at https://github.com/microgenomics/tutorials/blob/master/pangenome.md", 
            "title": "Input data"
        }, 
        {
            "location": "/dna/pan/roary/#run", 
            "text": "navigate into the place where the gff folder is.   roary -f ./results ./gff_files/*.gff   -f ./results  puts the output into a directory called results", 
            "title": "Run"
        }, 
        {
            "location": "/dna/pan/roary/#how-it-works", 
            "text": "Based on the input genomes, Roary works out which genes are shared between all (core) and which are not (accessory).  It uses the protein-coding genes from each of the input genomes.  converts to protein seqs  similar protein seqs are clustered progressively.  each sample: will be labelled with presence/absence of orthologous genes.", 
            "title": "How it works"
        }, 
        {
            "location": "/dna/pan/roary/#output", 
            "text": "", 
            "title": "Output"
        }, 
        {
            "location": "/dna/pan/roary/#summary-statistics", 
            "text": "more summary_statistics.txt   you will see the number of core genes, shell genes, etc.  q  to exit viewing", 
            "title": "summary statistics:"
        }, 
        {
            "location": "/dna/pan/roary/#gene-presenceabsence-graphically", 
            "text": "roary2svg.pl gene_presence_absence.csv   pan_genome.svg   (if you have logged in with -X -Y)   firefox pan_genome.svg     then  enter  the   makes it run in the background  a firefox window should open with the svg image  (later: close the firefox window to stop this job running in the background)", 
            "title": "gene presence/absence graphically:"
        }, 
        {
            "location": "/dna/pan/roary/#list-of-genes-that-are-presentabsent", 
            "text": "view the gene_presence_absence.csv by (FIXME)  lots of information about this file in the roary website (FIXME summarize?)", 
            "title": "list of genes that are present/absent:"
        }, 
        {
            "location": "/dna/pan/roary/#query-the-pan-genome", 
            "text": "copy the input .gff files into the results folder (FIXME: do this earlier)  cd into this folder   query_pan_genome -a intersection *.gff   this finds the core genes   more pan_genome_results   shows the list of genes found in the core genome.  q  to exit viewing", 
            "title": "query the pan genome:"
        }, 
        {
            "location": "/dna/pan/roary/#advanced-options", 
            "text": "FIXME: update firefox on mGVL so can run phandango", 
            "title": "Advanced options"
        }, 
        {
            "location": "/dna/pan/roary/#run-roary-and-create-an-alignment-of-core-genes", 
            "text": "roary -f ./results -e -n -p 8 ./gff_files/*.gff   -f ./results  puts the output into a directory called results  -e -n  creates an alignment of core genes using mafft  -p 8  gives 8 threads - optional, if you know how many you have", 
            "title": "Run roary and create an alignment of core genes:"
        }, 
        {
            "location": "/dna/pan/roary/#generate-a-tree-based-on-the-presenceabsence-of-core-genes", 
            "text": "navigate into the results folder that you want to use.   FastTree -nt -gtr core_gene_alignment.aln   my_tree.newick   (By default, roary will also have created a (very quick) tree from the accessory genes.)  FastTree information and options .", 
            "title": "Generate a tree based on the presence/absence of core genes:"
        }, 
        {
            "location": "/dna/pan/roary/#use-roary_plotspy-to-generate-plots", 
            "text": "navigate into the results folder that you want to use.   python roary_plots.py core_gene_alignment.nwk gene_presence_absence.csv   output: pangenome matrix, frequency plot, pie chart.  view these by typing  firefox [filename]  and a firefox window will open to show the image. You need to close the window before you open the next image.", 
            "title": "Use roary_plots.py to generate plots:"
        }, 
        {
            "location": "/dna/pan/roary/#what-next", 
            "text": "View using Phandango;  tutorial here.", 
            "title": "What next?"
        }, 
        {
            "location": "/dna/pan/roary/#more-information", 
            "text": "another Roary tutorial", 
            "title": "More information"
        }, 
        {
            "location": "/about/", 
            "text": "About\n\n\nThis site contains tutorials for using the\n\nMicrobial Genomics Virtual Lab\n to perform bioinformatics\ntasks on bacterial \nomics\n data, either on the Unix command line or using\nthe \nGalaxy\n system.\n\n\nAuthors\n\n\n\n\nAnna Syme\n\n\nTorsten Seemann\n\n\nMadison Flannery\n\n\nSimon Gladman\n\n\n\n\nFunding\n\n\n\n\nBioplatforms Australia\n\n\nResearch Data Services\n\n\nNectar", 
            "title": "About"
        }, 
        {
            "location": "/about/#about", 
            "text": "This site contains tutorials for using the Microbial Genomics Virtual Lab  to perform bioinformatics\ntasks on bacterial  omics  data, either on the Unix command line or using\nthe  Galaxy  system.", 
            "title": "About"
        }, 
        {
            "location": "/about/#authors", 
            "text": "Anna Syme  Torsten Seemann  Madison Flannery  Simon Gladman", 
            "title": "Authors"
        }, 
        {
            "location": "/about/#funding", 
            "text": "Bioplatforms Australia  Research Data Services  Nectar", 
            "title": "Funding"
        }
    ]
}